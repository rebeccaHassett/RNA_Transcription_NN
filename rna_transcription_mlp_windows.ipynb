{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35ba1335",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.utils.data as td\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "froot = './data/k562_main'\n",
    "\n",
    "df = pd.read_csv(froot + \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25c67eaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   seqnames    start      end strand  ensembl_gene_id  score      ctcf  \\\n",
      "0         1  3859709  3859709      +  ENSG00000169598    0.0 -0.010876   \n",
      "1         1  3859710  3859710      +  ENSG00000169598    0.0 -0.010887   \n",
      "2         1  3859711  3859711      +  ENSG00000169598    0.0 -0.010902   \n",
      "3         1  3859712  3859712      +  ENSG00000169598    0.0 -0.010920   \n",
      "4         1  3859713  3859713      +  ENSG00000169598    0.0 -0.010941   \n",
      "\n",
      "   h3k36me3   h3k4me1  h3k79me2  ...       sj3       dms      rpts  wgbs  \\\n",
      "0  0.353765 -0.078256 -0.156547  ... -0.057178 -0.307549  0.249626   0.0   \n",
      "1  0.347003 -0.077117 -0.155891  ... -0.057178 -0.307549  0.249626   0.0   \n",
      "2  0.340295 -0.075994 -0.155236  ... -0.057178 -0.307549  0.249626   0.0   \n",
      "3  0.333641 -0.074887 -0.154583  ... -0.057178 -0.307549  0.249626   0.0   \n",
      "4  0.327043 -0.073795 -0.153930  ... -0.057178 -0.307549  0.249626   0.0   \n",
      "\n",
      "       A         T         G         C  lambda_alphaj      zeta  \n",
      "0 -0.625 -0.678443  1.954571 -0.494439       0.014335  0.932859  \n",
      "1 -0.625 -0.678443  1.954571 -0.494439       0.014335  0.933402  \n",
      "2 -0.625  1.473964 -0.511621 -0.494439       0.014335  0.933944  \n",
      "3 -0.625  1.473964 -0.511621 -0.494439       0.014335  0.934485  \n",
      "4 -0.625 -0.678443  1.954571 -0.494439       0.014335  0.935024  \n",
      "\n",
      "[5 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b54d1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['gene_length'] = df.groupby('ensembl_gene_id')['ensembl_gene_id'].transform('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a8abcdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ctcf', 'h3k36me3', 'h3k4me1', 'h3k79me2', 'h3k9me1', 'h3k9me3', 'h4k20me1', 'sj5', 'sj3', 'dms', 'rpts', 'wgbs']\n",
      "['A', 'T', 'G', 'C']\n"
     ]
    }
   ],
   "source": [
    "column_names = df.columns.tolist()\n",
    "feature_names = column_names[6:-7]\n",
    "nucleotides = column_names[-7:-3]\n",
    "print(feature_names)\n",
    "print(nucleotides)\n",
    "\n",
    "# process read counts\n",
    "X_ji = df.groupby('ensembl_gene_id')['score'].apply(list).tolist() \n",
    "\n",
    "# process GLM simulated elongation rates\n",
    "Z_ji = df.groupby('ensembl_gene_id')['zeta'].apply(list).tolist() \n",
    "\n",
    "num_samples = len(X_ji)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40cae20e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1502\n"
     ]
    }
   ],
   "source": [
    "print(num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef3e2763",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window(data, window_size):\n",
    "    data = np.array(data)  # Convert data to a NumPy array for efficient operations\n",
    "    num_sites = len(data)\n",
    "    \n",
    "    sub_sequences = []\n",
    "    \n",
    "    for i in range(num_sites):\n",
    "        start = i - window_size // 2\n",
    "        end = i + window_size // 2 + 1  # +1 to include the right edge\n",
    "        \n",
    "        # Ensure that the window is within the bounds of the sequence\n",
    "        if start < 0:\n",
    "            padding_start = abs(start)\n",
    "            start = 0\n",
    "        else:\n",
    "            padding_start = 0\n",
    "        \n",
    "        if end > num_sites:\n",
    "            padding_end = end - num_sites\n",
    "            end = num_sites\n",
    "        else:\n",
    "            padding_end = 0\n",
    "        \n",
    "        window = data[start:end]\n",
    "        \n",
    "        # Pad the window if necessary\n",
    "        if padding_start > 0 or padding_end > 0:\n",
    "            window = np.pad(window, (padding_start, padding_end), mode='constant')\n",
    "        \n",
    "        sub_sequences.append(window)\n",
    "    \n",
    "    return sub_sequences\n",
    "\n",
    "window_size = 201  # 100 sites to the left, 100 sites to the right, and the target site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecb3e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ji_windows = []\n",
    "for seq in X_ji:\n",
    "    x_windows = sliding_window(seq, window_size)\n",
    "    X_ji_windows.extend(x_windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f77d389",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_ji_windows = []\n",
    "for seq in Z_ji:\n",
    "    z_windows = sliding_window(seq, window_size)\n",
    "    Z_ji_windows.extend(z_windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cffd98a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "C_j = df.groupby('ensembl_gene_id')['lambda_alphaj'].apply(list).tolist() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "195a1625",
   "metadata": {},
   "outputs": [],
   "source": [
    "C_j_windows = []\n",
    "for seq in C_j:\n",
    "    c_windows = sliding_window(seq, window_size)\n",
    "    C_j_windows.extend(c_windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e396e7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#Y_ji is a list of samples containing lists of their feature values\n",
    "    # [   \n",
    "    #   [[sample_1_feature_1], [sample_1_feature_2], [sample_1_feature_3]],\n",
    "    #   [[sample_2_feature_1], [sample_2_feature_2], [sample_2_feature_3]],  \n",
    "    # ]\n",
    "\n",
    "Y_ji = []\n",
    "\n",
    "for sample_id in df['ensembl_gene_id'].unique():\n",
    "    sample_data = [df[feature_name][df['ensembl_gene_id'] == sample_id].tolist() for feature_name in feature_names]\n",
    "    Y_ji.append(sample_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c660a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize features\n",
    "scaler = MinMaxScaler()\n",
    "Y_ji = np.array(Y_ji)\n",
    "# reshape dataset to [num_samples, num_features * feature_length]\n",
    "Y_ji_reshaped = Y_ji.reshape(Y_ji.shape[0], -1)\n",
    "normalized_Y_ji_reshaped = scaler.fit_transform(Y_ji_reshaped)\n",
    "Y_ji = normalized_Y_ji_reshaped.reshape(Y_ji.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "35f18812",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, X_ji, C_j, Z_ji):\n",
    "        #self.Y_ji = Y_ji\n",
    "        self.X_ji = X_ji\n",
    "        self.C_j = C_j\n",
    "        self.Z_ji = Z_ji\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X_ji)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            #'Y_ji':  torch.tensor(self.Y_ji[idx], dtype=torch.float32),\n",
    "            'X_ji': torch.tensor(self.X_ji[idx], dtype=torch.float32),\n",
    "            'C_j': torch.tensor(self.C_j[idx], dtype=torch.float32),\n",
    "            'Z_ji': torch.tensor(self.Z_ji[idx], dtype=torch.float32)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5977e736",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hassett/software/anaconda3/envs/cnn-motif/lib/python3.8/site-packages/torch/utils/data/dataset.py:348: UserWarning: Length of split at index 1 is 0. This might result in an empty dataset.\n",
      "  warnings.warn(f\"Length of split at index {i} is 0. \"\n"
     ]
    }
   ],
   "source": [
    "dataset = CustomDataset(X_ji, C_j, Z_ji)\n",
    "\n",
    "trnset, valset, tstset = td.random_split(dataset, [0.9,0,0.1])\n",
    "\n",
    "trndl = DataLoader(trnset, batch_size=16, shuffle=True)\n",
    "tstdl = DataLoader(tstset, batch_size=16, shuffle=False)\n",
    "valdl = DataLoader(valset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2404f7d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (fc1): Linear(in_features=201, out_features=150, bias=True)\n",
      "  (fc2): Linear(in_features=150, out_features=100, bias=True)\n",
      "  (fc3): Linear(in_features=100, out_features=50, bias=True)\n",
      "  (fc4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  (relu): ReLU()\n",
      ")\n",
      "torch.Size([16, 1])\n",
      "Number of parameters: 50501\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA90AAAJOCAYAAACqS2TfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABR7klEQVR4nO3deZiN9f/H8deZ1Rgzw5B9GFvKMshSEUXZlahoEaKyREnCFAkhUSmkKGvW7KIFWYpki0qWRrayZhmawWyf3x/95nwdMzSj+TjnjOfjuua65tz3fe7zPuee9znzOvfnvm+HMcYIAAAAAABkOR93FwAAAAAAQHZF6AYAAAAAwBJCNwAAAAAAlhC6AQAAAACwhNANAAAAAIAlhG4AAAAAACwhdAMAAAAAYAmhGwAAAAAASwjdAAAAAABYQugGAEiSfvrpJ3Xs2FGlSpVSUFCQgoKCVKZMGXXq1EmbN2++bnW8/vrrcjgcLtMiIyPVvn17q4+7fv16vf766zpz5ozVx7mSfv36qVixYvLz81Pu3LmvuFzq6+Pj46Pff/89zfy4uDiFhobK4XBk6Wu2f/9+ORwOTZ48OdP3Xb16tRwOh1avXp2h5VJ/fH19VaBAAT3yyCPauXPntRXuJeLj4/X666//62sEAPA+hG4AgD766CNVrVpVP/zwg1544QV9/vnnWrp0qXr06KEdO3aoevXq2rt3r9vqW7Bggfr372/1MdavX6+BAwe6JXQvWrRIQ4YMUdu2bbVmzRqtWLHiX++TK1cuTZo0Kc30zz77TImJifL397dR6nUxdOhQff/991q1apX69Omj5cuXq1atWvrzzz/dXZo18fHxGjhwIKEbALIhP3cXAABwr3Xr1qlr165q2rSp5s6dq4CAAOe8evXq6bnnntNnn32moKCgq64nPj5eOXPmtFJjlSpVrKzXU/zyyy+SpOeff1758+fP0H1at26tKVOmaODAgfLx+d936J988olatGihxYsXW6n1eihTpozuuOMOSVKdOnWUO3dudezYUZMnT9arr776n9Zt8+/UEyUmJsrhcMjPj3/5AMBd2NMNADe4oUOHytfXVx999JFL4L7UI488osKFCztvt2/fXrly5dLPP/+sBg0aKCQkRPfee68kafny5WrevLmKFi2qHDlyqHTp0urUqZP++uuvNOtdunSpKleurMDAQJUoUUIjR45M9/HTG15+9uxZ9erVSyVKlFBAQICKFCmiHj16KC4uzmU5h8Ohbt26adq0abr11luVM2dOVapUSZ9//rlzmddff10vv/yyJKlEiRLO4c2pex2/+eYb3XPPPcqbN6+CgoJUrFgxPfTQQ4qPj7/qa5uSkqK33npLt9xyiwIDA5U/f361bdtWf/zxh8tz69evnySpQIECcjgcev3116+6Xknq0KGDDh06pOXLlzun7dmzR9999506dOiQ7n0OHjyoNm3aKH/+/AoMDNStt96qt99+WykpKS7LHT58WK1atVJISIjCwsLUunVrHT16NN11bt68WQ888IDCw8OVI0cOValSRXPmzPnX+jMjNYAfOHBAkjR27FjVqVNH+fPnV3BwsCpWrKi33npLiYmJLve75557VKFCBa1du1Y1a9ZUzpw5na/N7Nmz1aBBAxUqVEhBQUG69dZb1bdv3zR/P6l/67t27VLDhg0VHBysQoUK6c0335QkbdiwQXfddZeCg4N18803a8qUKWnqP3r0qDp16qSiRYsqICBAJUqU0MCBA5WUlCTpn6H7N910kyRp4MCBzr+/S//mf/vtNz3++OMu227s2LEuj5M6PH/atGl66aWXVKRIEQUGBiomJkbx8fHOfsmRI4fCw8NVrVo1zZw581o3CwAgg/jaEwBuYMnJyVq1apWqVaumQoUKZeq+CQkJeuCBB9SpUyf17dvXGSD27t2rO++8U08//bTCwsK0f/9+vfPOO7rrrrv0888/O4c9r1y5Us2bN9edd96pWbNmKTk5WW+99ZaOHTv2r48dHx+vu+++W3/88YdeeeUVRUVFaceOHXrttdf0888/a8WKFS7HhS9dulSbNm3SoEGDlCtXLr311ltq0aKFdu/erZIlS+rpp5/WqVOnNHr0aM2fP9/5WpQrV0779+9X06ZNVbt2bU2cOFG5c+fWn3/+qS+//FIJCQlX3WvapUsXjR8/Xt26dVOzZs20f/9+9e/fX6tXr9bWrVuVL18+LViwQGPHjtUnn3yiL7/8UmFhYSpatOi/vgZlypRx1tSwYUNJ0sSJExUZGen8AuRSJ06cUM2aNZWQkKDBgwcrMjJSn3/+uXr16qW9e/fqgw8+kCSdP39e9913nw4fPqxhw4bp5ptv1tKlS9W6des061y1apUaNWqk22+/XR9++KHCwsI0a9YstW7dWvHx8Vl2THlMTIwkOYPp3r179fjjjzu/cNm+fbuGDBmiXbt2aeLEiS73PXLkiNq0aaPevXtr6NChzlEBv/32m5o0aaIePXooODhYu3bt0vDhw7Vx40Z98803LutITExUy5Yt1blzZ7388suaMWOGoqOjdfbsWc2bN099+vRR0aJFNXr0aLVv314VKlRQ1apVJf0TuGvUqCEfHx+99tprKlWqlL7//nu98cYb2r9/vyZNmqRChQrpyy+/VKNGjdSxY0c9/fTTLs/3119/Vc2aNVWsWDG9/fbbKliwoL766is9//zz+uuvvzRgwACXeqOjo3XnnXfqww8/lI+Pj/Lnz6+ePXtq2rRpeuONN1SlShXFxcXpl19+0cmTJ7NkGwEArsIAAG5YR48eNZLMo48+mmZeUlKSSUxMdP6kpKQ457Vr185IMhMnTrzq+lNSUkxiYqI5cOCAkWQWLVrknHf77bebwoULm/PnzzunnT171oSHh5vLP56KFy9u2rVr57w9bNgw4+PjYzZt2uSy3Ny5c40ks2zZMuc0SaZAgQLm7NmzLs/bx8fHDBs2zDltxIgRRpLZt29fuuvctm3bVZ/r5Xbu3Gkkma5du7pM/+GHH4wk88orrzinDRgwwEgyJ06c+Nf1XrrspEmTTGBgoDl58qRJSkoyhQoVMq+//roxxpjg4GCX16xv375Gkvnhhx9c1telSxfjcDjM7t27jTHGjBs3Ls22MsaYZ555xkgykyZNck675ZZbTJUqVUxiYqLLss2aNTOFChUyycnJxhhjVq1aZSSZVatWXfW5pS43e/Zsk5iYaOLj483atWtN6dKlja+vr9m+fXua+yQnJ5vExEQzdepU4+vra06dOuWcd/fddxtJZuXKlVd93NS/0zVr1hhJLo+T+rc+b94857TExERz0003GUlm69atzuknT540vr6+pmfPns5pnTp1Mrly5TIHDhxwecyRI0caSWbHjh3GGGNOnDhhJJkBAwakqa9hw4amaNGiJjY21mV6t27dTI4cOZzPOfX1q1OnTpp1VKhQwTz44INXfR0AAHYwvBwAkK6qVavK39/f+fP222+nWeahhx5KM+348ePq3LmzIiIi5OfnJ39/fxUvXlySnGegjouL06ZNm9SyZUvlyJHDed+QkBDdf//9/1rb559/rgoVKqhy5cpKSkpy/jRs2DDds2TXrVtXISEhztsFChRQ/vz5ncOVr6Zy5coKCAjQs88+qylTpqR7xvD0rFq1SpLS7O2tUaOGbr31Vq1cuTJD67maRx55RAEBAZo+fbqWLVumo0ePXnHv8jfffKNy5cqpRo0aLtPbt28vY4xz7+6qVasUEhKiBx54wGW5xx9/3OV2TEyMdu3apSeeeEKSXLZDkyZNdOTIEe3evfuanlfr1q3l7++vnDlzqk6dOkpOTtbcuXMVFRUlSfrxxx/1wAMPKG/evPL19ZW/v7/atm2r5ORk7dmzx2VdefLkUb169dI8xu+//67HH39cBQsWdK7j7rvvlqQ0Z0p3OBxq0qSJ87afn59Kly6tQoUKuZxvIDw8PM3f1eeff666deuqcOHCLq9R48aNJUlr1qy56mtx4cIFrVy5Ui1atFDOnDnTvM4XLlzQhg0bXO6TXl/WqFFDX3zxhfr27avVq1fr/PnzV31cAEDWYXg5ANzA8uXLp6CgoHTD54wZMxQfH68jR46kCWCSlDNnToWGhrpMS0lJUYMGDXT48GH1799fFStWVHBwsFJSUnTHHXc4/9E/ffq0UlJSVLBgwTTrTW/a5Y4dO6aYmJgrnqH78uPH8+bNm2aZwMDADAWPUqVKacWKFXrrrbf03HPPKS4uTiVLltTzzz+vF1544Yr3Sx22m96w/cKFC2co8P+b4OBgtW7dWhMnTlTx4sV13333Ob/gSK+eyMjIdGu5tN6TJ0+qQIECaZa7fLukHgbQq1cv9erVK93HTO84/owYPny46tWrJ19fX+XLl08RERHOeQcPHlTt2rVVtmxZvffee4qMjFSOHDm0ceNGPffcc2m2aXqv/99//63atWsrR44ceuONN3TzzTcrZ86cOnTokFq2bJlmHTlz5nT5ckiSAgICFB4enmbdAQEBunDhgvP2sWPHtGTJkgz/rV7u5MmTSkpK0ujRozV69OgMrSO95/z++++raNGimj17toYPH64cOXKoYcOGGjFihMqUKXPVGgAA/w2hGwBuYL6+vqpXr56+/vprHTlyxOWf9XLlykn65yRP6bn8WtrSP2fh3r59uyZPnqx27do5p6cek5sqT548cjgc6Z6c60on7LpU6pcFlx+/e+n8rFS7dm3Vrl1bycnJ2rx5s0aPHq0ePXqoQIECevTRR9O9T2rQP3LkSJpjtA8fPpxlNXbo0EEff/yxfvrpJ02fPv2Ky+XNm1dHjhxJM/3w4cOS/vea5c2bVxs3bkyz3OXbJXX56OhotWzZMt3HLFu2bMaexGVKliypatWqpTtv4cKFiouL0/z5812+YNi2bVu6y6f3d/rNN9/o8OHDWr16tXPvtiQrl4vLly+foqKiNGTIkHTnX3qCwvTkyZNHvr6+evLJJ/Xcc8+lu0yJEiVcbqf3nIODgzVw4EANHDhQx44dc+71vv/++7Vr164MPhsAwLUgdAPADS46OlpffPGFOnfurLlz5/6n6zun/rMfGBjoMv2jjz5yuR0cHKwaNWpo/vz5GjFihHMv4rlz57RkyZJ/fZxmzZpp6NChyps3b5rAca1Sa77a3m9fX1/dfvvtuuWWWzR9+nRt3br1iqE7dUjzp59+qurVqzunb9q0STt37vzPl75Kdeedd6pDhw6KjY1VixYtrrjcvffeq2HDhmnr1q267bbbnNOnTp0qh8OhunXrSvpnKP6cOXO0ePFilxEOM2bMcFlf2bJlVaZMGW3fvl1Dhw7NkueSEen9jRljNGHChP+0Dint32lWaNasmZYtW6ZSpUopT548V1zuSn9/OXPmVN26dfXjjz8qKirqilcYyIwCBQqoffv22r59u0aNGnXDXUYNAK43QjcA3OBq1aqlsWPHqnv37rrtttv07LPPqnz58vLx8dGRI0c0b948SUozlDw9t9xyi0qVKqW+ffvKGKPw8HAtWbLE5bJWqQYPHqxGjRqpfv36eumll5ScnKzhw4crODhYp06duurj9OjRQ/PmzVOdOnX04osvKioqSikpKTp48KC+/vprvfTSS7r99tsz9TpUrFhRkvTee++pXbt28vf3V9myZTV9+nR98803atq0qYoVK6YLFy4497Dfd999V1xf2bJl9eyzz2r06NHy8fFR48aNnWcvj4iI0Isvvpip+q7mk08++ddlXnzxRU2dOlVNmzbVoEGDVLx4cS1dulQffPCBunTpoptvvlmS1LZtW7377rtq27athgwZojJlymjZsmX66quv0qzzo48+UuPGjdWwYUO1b99eRYoU0alTp7Rz505t3bpVn332WZY9x1T169dXQECAHnvsMfXu3VsXLlzQuHHjdPr06Qyvo2bNmsqTJ486d+6sAQMGyN/fX9OnT9f27duzvN5BgwZp+fLlqlmzpp5//nmVLVtWFy5c0P79+7Vs2TJ9+OGHKlq0qEJCQlS8eHEtWrRI9957r8LDw5UvXz5FRkbqvffe01133aXatWurS5cuioyM1Llz5xQTE6MlS5akOdt6em6//XY1a9ZMUVFRypMnj3bu3Klp06bpzjvvJHADgGWEbgCAOnfurDvvvFPvvfee3n33XR0+fFgOh0NFixZVzZo1tXLlynRPRnU5f39/LVmyRC+88II6deokPz8/3XfffVqxYoWKFSvmsmz9+vW1cOFC9evXT61bt1bBggXVtWtXnT9/XgMHDrzq4wQHB+vbb7/Vm2++qfHjx2vfvn3O62ffd9996R67/G/uueceRUdHa8qUKZowYYJSUlK0atUqVa5cWV9//bUGDBigo0ePKleuXKpQoYIWL16sBg0aXHWd48aNU6lSpfTJJ59o7NixCgsLU6NGjTRs2LB0jzO36aabbtL69esVHR3tvNxVyZIl9dZbb6lnz57O5XLmzKlvvvlGL7zwgvr27SuHw6EGDRpo1qxZqlmzpss669atq40bN2rIkCHq0aOHTp8+rbx586pcuXJq1aqVledxyy23aN68eerXr59atmypvHnz6vHHH1fPnj2dJyf7N3nz5tXSpUv10ksvqU2bNgoODlbz5s01e/Zsl1EAWaFQoULavHmzBg8erBEjRuiPP/5QSEiISpQooUaNGrns/f7kk0/08ssv64EHHtDFixfVrl07TZ48WeXKldPWrVs1ePBg9evXT8ePH1fu3LlVpkwZlxO8XU29evW0ePFivfvuu4qPj1eRIkXUtm3bLBtxAQC4Mocxxri7CAAAAAAAsiMuGQYAAAAAgCWEbgAAAAAALCF0AwAAAABgCaEbAAAAAABLCN0AAAAAAFhC6AYAAAAAwBKvvk53SkqKDh8+rJCQEDkcDneXAwAAAAC4QRhjdO7cORUuXFg+Plfen+3Vofvw4cOKiIhwdxkAAAAAgBvUoUOHVLRo0SvO9+rQHRISIumfJxkaGurmagAAAAAAN4qzZ88qIiLCmUuvxKtDd+qQ8tDQUEI3AAAAAOC6+7dDnTmRGgAAAAAAlhC6AQAAAACwhNANAAAAAIAlhG4AAAAAACwhdAMAAAAAYAmhGwAAAAAASwjdAAAAAABYQugGAAAAAMASQjcAAAAAAJYQugEAAAAAsITQDQAAAACAJYRuAAAAAAAsIXQDAAAAAGAJoRsAAAAAAEsI3QAAAAAAWELoBgAAAADAEkI3AAAAAACWELoBAAAAALCE0A0AAAAAgCWEbgAAAAAALPFzdwEAAMA7RPZd6u4Ssq39bzZ1dwkAAEvY0w0AAAAAgCWEbgAAAAAALCF0AwAAAABgCaEbAAAAAABLCN0AAAAAAFhC6AYAAAAAwBJCNwAAAAAAlhC6AQAAAACwhNANAAAAAIAlfu4uAACySmTfpe4uIdva/2ZTd5cAAADgldjTDQAAAACAJYRuAAAAAAAsIXQDAAAAAGAJoRsAAAAAAEsI3QAAAAAAWELoBgAAAADAEkI3AAAAAACWELoBAAAAALCE0A0AAAAAgCWEbgAAAAAALCF0AwAAAABgCaEbAAAAAABLCN0AAAAAAFhC6AYAAAAAwBJCNwAAAAAAlhC6AQAAAACwhNANAAAAAIAlhG4AAAAAACwhdAMAAAAAYAmhGwAAAAAASwjdAAAAAABYQugGAAAAAMASQjcAAAAAAJYQugEAAAAAsITQDQAAAACAJYRuAAAAAAAscWvoTkpKUr9+/VSiRAkFBQWpZMmSGjRokFJSUtxZFgAAAAAAWcLPnQ8+fPhwffjhh5oyZYrKly+vzZs366mnnlJYWJheeOEFd5YGAAAAAMB/5tbQ/f3336t58+Zq2rSpJCkyMlIzZ87U5s2b3VkWAAAAAABZwq3Dy++66y6tXLlSe/bskSRt375d3333nZo0aZLu8hcvXtTZs2ddfgAAAAAA8FRu3dPdp08fxcbG6pZbbpGvr6+Sk5M1ZMgQPfbYY+kuP2zYMA0cOPA6VwkAAAAAwLVx657u2bNn69NPP9WMGTO0detWTZkyRSNHjtSUKVPSXT46OlqxsbHOn0OHDl3nigEAAAAAyDi37ul++eWX1bdvXz366KOSpIoVK+rAgQMaNmyY2rVrl2b5wMBABQYGXu8ys0xk36XuLiFb2v9mU3eXAAAAAADpcuue7vj4ePn4uJbg6+vLJcMAAAAAANmCW/d033///RoyZIiKFSum8uXL68cff9Q777yjDh06uLMsAAAAAACyhFtD9+jRo9W/f3917dpVx48fV+HChdWpUye99tpr7iwLAAAAAIAs4dbQHRISolGjRmnUqFHuLAMAAAAAACvcekw3AAAAAADZGaEbAAAAAABLCN0AAAAAAFhC6AYAAAAAwBJCNwAAAAAAlhC6AQAAAACwhNANAAAAAIAlhG4AAAAAACwhdAMAAAAAYAmhGwAAAAAASwjdAAAAAABYQugGAAAAAMASQjcAAAAAAJYQugEAAAAAsITQDQAAAACAJYRuAAAAAAAsIXQDAAAAAGAJoRsAAAAAAEsI3QAAAAAAWELoBgAAAADAEkI3AAAAAACWELoBAAAAALCE0A0AAAAAgCWEbgAAAAAALCF0AwAAAABgCaEbAAAAAABLCN0AAAAAAFhC6AYAAAAAwBJCNwAAAAAAlhC6AQAAAACwhNANAAAAAIAlhG4AAAAAACwhdAMAAAAAYAmhGwAAAAAASwjdAAAAAABYQugGAAAAAMASQjcAAAAAAJYQugEAAAAAsITQDQAAAACAJYRuAAAAAAAsIXQDAAAAAGAJoRsAAAAAAEsI3QAAAAAAWELoBgAAAADAEkI3AAAAAACWELoBAAAAALCE0A0AAAAAgCWEbgAAAAAALCF0AwAAAABgCaEbAAAAAABLCN0AAAAAAFhC6AYAAAAAwBJCNwAAAAAAlhC6AQAAAACwhNANAAAAAIAlhG4AAAAAACwhdAMAAAAAYAmhGwAAAAAASwjdAAAAAABYQugGAAAAAMASQjcAAAAAAJYQugEAAAAAsITQDQAAAACAJYRuAAAAAAAsIXQDAAAAAGAJoRsAAAAAAEsI3QAAAAAAWELoBgAAAADAEkI3AAAAAACWELoBAAAAALCE0A0AAAAAgCWEbgAAAAAALCF0AwAAAABgCaEbAAAAAABLCN0AAAAAAFhC6AYAAAAAwBJCNwAAAAAAlhC6AQAAAACwxM/dBQAAAACQIvsudXcJ2db+N5u6uwTcwNjTDQAAAACAJYRuAAAAAAAsIXQDAAAAAGAJoRsAAAAAAEsI3QAAAAAAWELoBgAAAADAEkI3AAAAAACWELoBAAAAALCE0A0AAAAAgCWEbgAAAAAALCF0AwAAAABgCaEbAAAAAABLCN0AAAAAAFji9tD9559/qk2bNsqbN69y5sypypUra8uWLe4uCwAAAACA/8zPnQ9++vRp1apVS3Xr1tUXX3yh/Pnza+/evcqdO7c7ywIAAAAAIEu4NXQPHz5cERERmjRpknNaZGSk+woCAAAAACALuXV4+eLFi1WtWjU98sgjyp8/v6pUqaIJEya4syQAAAAAALKMW0P377//rnHjxqlMmTL66quv1LlzZz3//POaOnVqustfvHhRZ8+edfkBAAAAAMBTuXV4eUpKiqpVq6ahQ4dKkqpUqaIdO3Zo3Lhxatu2bZrlhw0bpoEDB17vMgEAAAAAuCZu3dNdqFAhlStXzmXarbfeqoMHD6a7fHR0tGJjY50/hw4duh5lAgAAAABwTdy6p7tWrVravXu3y7Q9e/aoePHi6S4fGBiowMDA61EaAAAAAAD/mVv3dL/44ovasGGDhg4dqpiYGM2YMUPjx4/Xc889586yAAAAAADIEm4N3dWrV9eCBQs0c+ZMVahQQYMHD9aoUaP0xBNPuLMsAAAAAACyhFuHl0tSs2bN1KxZM3eXAQAAAABAlnPrnm4AAAAAALIzQjcAAAAAAJYQugEAAAAAsITQDQAAAACAJYRuAAAAAAAsIXQDAAAAAGAJoRsAAAAAAEsI3QAAAAAAWELoBgAAAADAEkI3AAAAAACWELoBAAAAALCE0A0AAAAAgCWEbgAAAAAALCF0AwAAAABgCaEbAAAAAABLCN0AAAAAAFjil9k7GGM0d+5crVq1SsePH1dKSorL/Pnz52dZcQAAAAAAeLNMh+4XXnhB48ePV926dVWgQAE5HA4bdQEAAAAA4PUyHbo//fRTzZ8/X02aNLFRDwAAAAAA2Uamj+kOCwtTyZIlbdQCAAAAAEC2kunQ/frrr2vgwIE6f/68jXoAAAAAAMg2Mj28/JFHHtHMmTOVP39+RUZGyt/f32X+1q1bs6w4AAAAAAC8WaZDd/v27bVlyxa1adOGE6kBAAAAAHAVmQ7dS5cu1VdffaW77rrLRj0AAAAAAGQbmT6mOyIiQqGhoTZqAQAAAAAgW8l06H777bfVu3dv7d+/30I5AAAAAABkH5keXt6mTRvFx8erVKlSypkzZ5oTqZ06dSrLigMAAAAAwJtlOnSPGjXKQhkAAAAAAGQ/mQrdiYmJWr16tfr376+SJUvaqgkAAAAAgGwhU8d0+/v7a8GCBbZqAQAAAAAgW8n0idRatGihhQsXWigFAAAAAIDsJdPHdJcuXVqDBw/W+vXrVbVqVQUHB7vMf/7557OsOAAAAAAAvFmmQ/fHH3+s3Llza8uWLdqyZYvLPIfDQegGAAAAAOD/ZTp079u3z0YdAAAAAABkO5k+pvtSxhgZY7KqFgAAAAAAspVrCt1Tp05VxYoVFRQUpKCgIEVFRWnatGlZXRsAAAAAAF4t08PL33nnHfXv31/dunVTrVq1ZIzRunXr1LlzZ/3111968cUXbdQJAAAAAIDXyXToHj16tMaNG6e2bds6pzVv3lzly5fX66+/TugGAAAAAOD/ZXp4+ZEjR1SzZs0002vWrKkjR45kSVEAAAAAAGQHmQ7dpUuX1pw5c9JMnz17tsqUKZMlRQEAAAAAkB1kenj5wIED1bp1a61du1a1atWSw+HQd999p5UrV6YbxgEAAAAAuFFlek/3Qw89pB9++EH58uXTwoULNX/+fOXLl08bN25UixYtbNQIAAAAAIBXyvSebkmqWrWqPv3006yuBQAAAACAbOWartMNAAAAAAD+XYb3dPv4+MjhcFx1GYfDoaSkpP9cFAAAAAAA2UGGQ/eCBQuuOG/9+vUaPXq0jDFZUhQAAAAAANlBhkN38+bN00zbtWuXoqOjtWTJEj3xxBMaPHhwlhYHAAAAAIA3u6Zjug8fPqxnnnlGUVFRSkpK0rZt2zRlyhQVK1Ysq+sDAAAAAMBrZSp0x8bGqk+fPipdurR27NihlStXasmSJapQoYKt+gAAAAAA8FoZHl7+1ltvafjw4SpYsKBmzpyZ7nBzAAAAAADwPxkO3X379lVQUJBKly6tKVOmaMqUKekuN3/+/CwrDgAAAAAAb5bh0N22bdt/vWQYAAAAAAD4nwyH7smTJ1ssAwAAAACA7Oeazl4OAAAAAAD+HaEbAAAAAABLCN0AAAAAAFhC6AYAAAAAwJJMh+61a9cqKSkpzfSkpCStXbs2S4oCAAAAACA7yHTorlu3rk6dOpVmemxsrOrWrZslRQEAAAAAkB1kOnQbY9K9XvfJkycVHBycJUUBAAAAAJAdZPg63S1btpQkORwOtW/fXoGBgc55ycnJ+umnn1SzZs2srxAAAAAAAC+V4dAdFhYm6Z893SEhIQoKCnLOCwgI0B133KFnnnkm6ysEAAAAAMBLZTh0T5o0SZIUGRmpXr16MZQcAAAAAIB/keHQnWrAgAE26gAAAAAAINvJ9InUjh07pieffFKFCxeWn5+ffH19XX4AAAAAAMA/Mr2nu3379jp48KD69++vQoUKpXsmcwAAAAAAcA2h+7vvvtO3336rypUrWygHAAAAAIDsI9PDyyMiImSMsVELAAAAAADZSqZD96hRo9S3b1/t37/fQjkAAAAAAGQfmR5e3rp1a8XHx6tUqVLKmTOn/P39XeafOnUqy4oDAAAAAMCbZTp0jxo1ykIZAAAAAABkP5kO3e3atbNRBwAAAAAA2U6mj+mWpL1796pfv3567LHHdPz4cUnSl19+qR07dmRpcQAAAAAAeLNMh+41a9aoYsWK+uGHHzR//nz9/fffkqSffvpJAwYMyPICAQAAAADwVpkO3X379tUbb7yh5cuXKyAgwDm9bt26+v7777O0OAAAAAAAvFmmQ/fPP/+sFi1apJl+00036eTJk1lSFAAAAAAA2UGmQ3fu3Ll15MiRNNN//PFHFSlSJEuKAgAAAAAgO8h06H788cfVp08fHT16VA6HQykpKVq3bp169eqltm3b2qgRAAAAAACvlOnQPWTIEBUrVkxFihTR33//rXLlyqlOnTqqWbOm+vXrZ6NGAAAAAAC8Uqav0+3v76/p06dr0KBB+vHHH5WSkqIqVaqoTJkyNuoDAAAAAMBrZTp0pypVqpRKlSqVlbUAAAAAAJCtZCh09+zZU4MHD1ZwcLB69ux51WXfeeedLCkMAAAAAABvl6HQ/eOPPyoxMdH5+5U4HI6sqQoAAAAAgGwgQ6F71apV6f4OAAAAAACuLNNnLwcAAAAAABmToT3dLVu2zPAK58+ff83FAAAAAACQnWRoT3dYWJjzJzQ0VCtXrtTmzZud87ds2aKVK1cqLCzMWqEAAAAAAHibDO3pnjRpkvP3Pn36qFWrVvrwww/l6+srSUpOTlbXrl0VGhpqp0oAAAAAALxQpo/pnjhxonr16uUM3JLk6+urnj17auLEiVlaHAAAAAAA3izToTspKUk7d+5MM33nzp1KSUnJkqIAAAAAAMgOMjS8/FJPPfWUOnTooJiYGN1xxx2SpA0bNujNN9/UU089leUFAgAAAADgrTIdukeOHKmCBQvq3Xff1ZEjRyRJhQoVUu/evfXSSy9leYEAAAAAAHirTIduHx8f9e7dW71799bZs2cliROoAQAAAACQjkwf032p0NDQLAvcw4YNk8PhUI8ePbJkfQAAAAAAuFum93RL0ty5czVnzhwdPHhQCQkJLvO2bt2a6fVt2rRJ48ePV1RU1LWUAwAAAACAR8r0nu73339fTz31lPLnz68ff/xRNWrUUN68efX777+rcePGmS7g77//1hNPPKEJEyYoT548mb4/AAAAAACeKtOh+4MPPtD48eM1ZswYBQQEqHfv3lq+fLmef/55xcbGZrqA5557Tk2bNtV9992X6fsCAAAAAODJMj28/ODBg6pZs6YkKSgoSOfOnZMkPfnkk7rjjjs0ZsyYDK9r1qxZ2rp1qzZt2pSh5S9evKiLFy86b6eeyA0AAAAAAE+U6T3dBQsW1MmTJyVJxYsX14YNGyRJ+/btkzEmw+s5dOiQXnjhBX366afKkSNHhu4zbNgwhYWFOX8iIiIyWz4AAAAAANdNpkN3vXr1tGTJEklSx44d9eKLL6p+/fpq3bq1WrRokeH1bNmyRcePH1fVqlXl5+cnPz8/rVmzRu+//778/PyUnJyc5j7R0dGKjY11/hw6dCiz5QMAAAAAcN1kenj5+PHjlZKSIknq3LmzwsPD9d133+n+++9X586dM7yee++9Vz///LPLtKeeekq33HKL+vTpI19f3zT3CQwMVGBgYGZLBgAAAADALTIVupOSkjRkyBB16NDBObS7VatWatWqVaYfOCQkRBUqVHCZFhwcrLx586aZDgAAAACAN8rU8HI/Pz+NGDEi3aHfAAAAAADAVaaHl993331avXq12rdvn+XFrF69OsvXCQAAAACAu2Q6dDdu3FjR0dH65ZdfVLVqVQUHB7vMf+CBB7KsOAAAAAAAvFmmQ3eXLl0kSe+8806aeQ6Hg6HnAAAAAAD8v0yH7tQzlwMAAAAAgKvL9HW6AQAAAABAxmR4T/f58+e1cuVKNWvWTJIUHR2tixcvOuf7+vpq8ODBypEjR9ZXCQAAAACAF8pw6J46dao+//xzZ+geM2aMypcvr6CgIEnSrl27VLhwYb344ot2KgUAAAAAwMtkeHj59OnT1aFDB5dpM2bM0KpVq7Rq1SqNGDFCc+bMyfICAQAAAADwVhkO3Xv27NHNN9/svJ0jRw75+Pzv7jVq1NCvv/6atdUBAAAAAODFMjy8PDY2Vn5+/1v8xIkTLvNTUlJcjvEGAAAAAOBGl+E93UWLFtUvv/xyxfk//fSTihYtmiVFAQAAAACQHWQ4dDdp0kSvvfaaLly4kGbe+fPnNXDgQDVt2jRLiwMAAAAAwJtleHj5K6+8ojlz5qhs2bLq1q2bbr75ZjkcDu3atUtjxoxRUlKSXnnlFZu1AgAAAADgVTIcugsUKKD169erS5cu6tu3r4wxkiSHw6H69evrgw8+UIECBawVCgAAAACAt8lw6JakEiVK6Msvv9SpU6cUExMjSSpdurTCw8OtFAcAAAAAgDfLVOhOFR4erho1amR1LQAAAAAAZCsZPpEaAAAAAADIHEI3AAAAAACWELoBAAAAALCE0A0AAAAAgCWEbgAAAAAALCF0AwAAAABgCaEbAAAAAABLCN0AAAAAAFhC6AYAAAAAwBJCNwAAAAAAlhC6AQAAAACwhNANAAAAAIAlhG4AAAAAACwhdAMAAAAAYAmhGwAAAAAASwjdAAAAAABYQugGAAAAAMASQjcAAAAAAJYQugEAAAAAsITQDQAAAACAJYRuAAAAAAAsIXQDAAAAAGAJoRsAAAAAAEsI3QAAAAAAWELoBgAAAADAEkI3AAAAAACWELoBAAAAALCE0A0AAAAAgCWEbgAAAAAALCF0AwAAAABgCaEbAAAAAABLCN0AAAAAAFhC6AYAAAAAwBJCNwAAAAAAlhC6AQAAAACwhNANAAAAAIAlhG4AAAAAACwhdAMAAAAAYAmhGwAAAAAASwjdAAAAAABYQugGAAAAAMASQjcAAAAAAJYQugEAAAAAsITQDQAAAACAJYRuAAAAAAAsIXQDAAAAAGAJoRsAAAAAAEsI3QAAAAAAWELoBgAAAADAEkI3AAAAAACWELoBAAAAALCE0A0AAAAAgCWEbgAAAAAALCF0AwAAAABgCaEbAAAAAABLCN0AAAAAAFhC6AYAAAAAwBJCNwAAAAAAlhC6AQAAAACwhNANAAAAAIAlhG4AAAAAACwhdAMAAAAAYAmhGwAAAAAASwjdAAAAAABYQugGAAAAAMASQjcAAAAAAJYQugEAAAAAsITQDQAAAACAJYRuAAAAAAAsIXQDAAAAAGAJoRsAAAAAAEsI3QAAAAAAWELoBgAAAADAEkI3AAAAAACWELoBAAAAALCE0A0AAAAAgCWEbgAAAAAALCF0AwAAAABgiVtD97Bhw1S9enWFhIQof/78evDBB7V79253lgQAAAAAQJZxa+hes2aNnnvuOW3YsEHLly9XUlKSGjRooLi4OHeWBQAAAABAlvBz54N/+eWXLrcnTZqk/Pnza8uWLapTp46bqgIAAAAAIGu4NXRfLjY2VpIUHh6e7vyLFy/q4sWLzttnz569LnUBAAAAAHAtPOZEasYY9ezZU3fddZcqVKiQ7jLDhg1TWFiY8yciIuI6VwkAAAAAQMZ5TOju1q2bfvrpJ82cOfOKy0RHRys2Ntb5c+jQoetYIQAAAAAAmeMRw8u7d++uxYsXa+3atSpatOgVlwsMDFRgYOB1rAwAAAAAgGvn1tBtjFH37t21YMECrV69WiVKlHBnOQAAAAAAZCm3hu7nnntOM2bM0KJFixQSEqKjR49KksLCwhQUFOTO0gAAAAAA+M/cekz3uHHjFBsbq3vuuUeFChVy/syePdudZQEAAAAAkCXcPrwcAAAAAIDsymPOXg4AAAAAQHZD6AYAAAAAwBJCNwAAAAAAlhC6AQAAAACwhNANAAAAAIAlhG4AAAAAACwhdAMAAAAAYAmhGwAAAAAASwjdAAAAAABYQugGAAAAAMASQjcAAAAAAJYQugEAAAAAsITQDQAAAACAJYRuAAAAAAAsIXQDAAAAAGAJoRsAAAAAAEsI3QAAAAAAWELoBgAAAADAEkI3AAAAAACWELoBAAAAALCE0A0AAAAAgCWEbgAAAAAALCF0AwAAAABgCaEbAAAAAABLCN0AAAAAAFhC6AYAAAAAwBJCNwAAAAAAlhC6AQAAAACwhNANAAAAAIAlhG4AAAAAACwhdAMAAAAAYAmhGwAAAAAASwjdAAAAAABYQugGAAAAAMASQjcAAAAAAJYQugEAAAAAsITQDQAAAACAJYRuAAAAAAAsIXQDAAAAAGAJoRsAAAAAAEsI3QAAAAAAWELoBgAAAADAEj93FwAAAAAA3iiy71J3l5Bt7X+zqbtLyDLs6QYAAAAAwBL2dAMAAGRT7IWzIzvtgQNgH3u6AQAAAACwhNANAAAAAIAlDC8HALgFw17tYegrAACegz3dAAAAAABYQugGAAAAAMASQjcAAAAAAJYQugEAAAAAsITQDQAAAACAJYRuAAAAAAAs4ZJhwBVwOSN7uJwRAAAAbhTs6QYAAAAAwBJCNwAAAAAAlhC6AQAAAACwhNANAAAAAIAlhG4AAAAAACwhdAMAAAAAYAmhGwAAAAAASwjdAAAAAABYQugGAAAAAMASQjcAAAAAAJYQugEAAAAAsITQDQAAAACAJYRuAAAAAAAsIXQDAAAAAGAJoRsAAAAAAEsI3QAAAAAAWELoBgAAAADAEkI3AAAAAACWELoBAAAAALCE0A0AAAAAgCWEbgAAAAAALCF0AwAAAABgCaEbAAAAAABLCN0AAAAAAFhC6AYAAAAAwBJCNwAAAAAAlhC6AQAAAACwhNANAAAAAIAlhG4AAAAAACwhdAMAAAAAYAmhGwAAAAAASwjdAAAAAABYQugGAAAAAMASQjcAAAAAAJYQugEAAAAAsITQDQAAAACAJYRuAAAAAAAscXvo/uCDD1SiRAnlyJFDVatW1bfffuvukgAAAAAAyBJuDd2zZ89Wjx499Oqrr+rHH39U7dq11bhxYx08eNCdZQEAAAAAkCXcGrrfeecddezYUU8//bRuvfVWjRo1ShERERo3bpw7ywIAAAAAIEu4LXQnJCRoy5YtatCggcv0Bg0aaP369W6qCgAAAACArOPnrgf+66+/lJycrAIFCrhML1CggI4ePZrufS5evKiLFy86b8fGxkqSzp49a6/QLJRyMd7dJWRLtrY/28setpn3sbHN2F720GPeh23mXdhe3odt5n28IeOl1miMuepybgvdqRwOh8ttY0yaaamGDRumgQMHppkeERFhpTZ4h7BR7q4AmcU28z5sM+/C9vI+bDPvwvbyPmwz7+NN2+zcuXMKCwu74ny3he58+fLJ19c3zV7t48ePp9n7nSo6Olo9e/Z03k5JSdGpU6eUN2/eKwZ1ZN7Zs2cVERGhQ4cOKTQ01N3lIAPYZt6F7eV92Gbehe3lfdhm3odt5l3YXnYYY3Tu3DkVLlz4qsu5LXQHBASoatWqWr58uVq0aOGcvnz5cjVv3jzd+wQGBiowMNBlWu7cuW2WeUMLDQ2lKb0M28y7sL28D9vMu7C9vA/bzPuwzbwL2yvrXW0Pdyq3Di/v2bOnnnzySVWrVk133nmnxo8fr4MHD6pz587uLAsAAAAAgCzh1tDdunVrnTx5UoMGDdKRI0dUoUIFLVu2TMWLF3dnWQAAAAAAZAm3n0ita9eu6tq1q7vLwCUCAwM1YMCANEP54bnYZt6F7eV92Gbehe3lfdhm3odt5l3YXu7lMP92fnMAAAAAAHBNfNxdAAAAAAAA2RWhGwAAAAAASwjdAAAAAABYQugGAAAAAMASQjcAAAAAAJYQunFdxcfHu7sEIFujxwC76DHALnoM2RGhG1Z988032rdvnySpf//+mj59ulJSUtxcFSQp9WqBf/31l86fP+/manCt6DHPRY9lD/SY56LHsgd6zHPRY1nHz90FIPv6888/NWjQICUkJKhcuXKaMmWKfvzxR/n48F2Puxlj5HA4tGTJEr377rvq06eP6tSpo6CgIHeXhkygxzwXPZY90GOeix7LHugxz0WPZS3+omFNkSJF9Nprr+nAgQP69NNPtXDhQlWoUEFJSUnuLu2G53A4tHDhQj3++OO69957VaZMGd5EvRA95rnoseyBHvNc9Fj2QI95LnosazlM6rgBIAulpKTIx8dHW7duVceOHRUQEKCgoCBNmDBBZcqUUXJysnx9fd1d5g3r4MGDuu+++9S9e3d1795dycnJSklJ0datW5UvXz6VKlXK3SXiX9Bjno0e8370mGejx7wfPebZ6LGsxZ5uZKnk5GRJcg4LKl++vNauXauBAwfK399fHTp0UExMjMub6Llz59xS640sMTFRoaGhqlGjhk6cOKG3335b9evXV4MGDdShQwctX77c3SXiCugx70CPeS96zDvQY96LHvMO9FjWInQjy6SkpDjfIBctWqQ5c+Zo5cqVCgkJUaNGjdS9e3flyJFDTz/9tGJiYiRJbdu21aJFi9xZ9g3j0kEtISEh+uOPP/TKK6+ofPny2rBhg5o0aaJFixbp1KlT2rVrlxsrxZXQY56NHvN+9Jhno8e8Hz3m2egxiwzwHz300EPmlVdecd5+6aWXTGhoqClbtqzx9/c3L730knPe4sWLTYMGDUz+/PlNrVq1TEREhElMTHRH2TeMlJQUY4wx586dMykpKebvv/82xhizZ88e079/fzNq1Chz/Phx5/INGzY0I0eOdEutSB895tnoMe9Hj3k2esz70WOejR6zj9CN/yQxMdEMGzbM+Pn5mTfffNOcPHnSVK9e3Wzbts3s37/fzJo1ywQFBZnOnTs777NlyxYzcuRIEx0d7XwTTUpKctdTyNZS30S/+OIL06JFC1OrVi3z9NNPmy1bthhjjLl48aJz2cTERBMdHW3y589vfvvtN7fUi7ToMc9Gj3k/esyz0WPejx7zbPTY9UHoxn928eJFM2bMGONwOEz79u1Nx44dTUJCgnP+woULTVBQkOnatWu69+dN1K6FCxeanDlzmtdee82MGDHCPPDAA6ZEiRJm8+bNxhhjkpOTzaRJk8z9999vihYtarZu3erminE5esyz0WPejx7zbPSY96PHPBs9Zh+hG9fs0jfA1DfTXLlymapVq6ZZduHChSZXrlzmiSeeuJ4l3nBOnDjhcvvXX381lSpVMh9++KExxpjDhw+bIkWKmIiICJM/f37nm+nu3bvNyy+/bHbv3n3da8aV0WOehx7LXugxz0OPZS/0mOehx9yD0I3/7PTp08YYY+Lj481HH31kfH19zeDBg9MsN2vWLFOvXj2TnJx8nSu8MbzyyivmwQcfdBkGtH37dvPss8+a8+fPm4MHD5oyZcqYZ555xmzatMmUK1fOFCtWzKxfv94Yw7fInowe8wz0WPZFj3kGeiz7osc8Az3mPoRuZNqlb4RTpkwxkZGRzuM6Ll68aEaPHm18fHzM0KFDM7QOZI19+/aZn376yRhjTFxcnHP6gQMHjDHGPPPMM6Z169bmwoULxph/TmqSI0cOU7p0aRMfH+88pgfuR495Jnos+6DHPBM9ln3QY56JHnMfLhmGTElJSXFeV3HBggU6e/asDhw4oGeeeUa///67AgIC9Oyzz+q9995T//79NXz48HTXk7oOZI3k5GRFRkaqYsWKWrFihR588EHt3LlTklSsWDHFxcXpp59+0m233abAwEClpKQoX758Gj9+vNatW6egoCA5HA43PwtI9JinoseyD3rMM9Fj2Qc95pnoMTdzd+qHd+rTp48pXLiwGTlypOnSpYspWbKkiYqKMnv37jXGGJOQkGDGjh1rHA6HmTp1qpurvbHs3bvX+Pn5maZNm5o9e/Y4pz/22GOmUqVK5vPPPzcvvviiKV68uPObTXgeesxz0WPZAz3mueix7IEe81z02PVH6Ma/On/+vMvtX375xRQsWNAsWbLEOS0mJsZERUWZypUrm5iYGGOMMRcuXDBz587l2ooWXWmYT0xMjMmTJ49p1KiR8810zZo1pmHDhqZw4cKmfPnyzktBwP3oMc9Fj2UP9JjnoseyB3rMc9FjnoHQjau66667zOzZs12mbdy40YSHh5tdu3YZY/53zM22bdtM7ty5Tb169cy+ffuMMf874QJvplkr9TIbqa/vrl27zMqVK81vv/1mjh07ZowxZs+ePSZPnjymQYMGzu1x/vx589tvv6U5cyXchx7zTPRY9kGPeSZ6LPugxzwTPeZZCN24qjFjxjhPppDavBcvXjRFihQx0dHRLsueOnXKVKtWzYSGhrpcCoKTLmStDz/80HzwwQfm7Nmzxhhj5syZY8LDw03hwoVNRESEuffee826deuMMf+8mYaHh5vGjRs7P/jgWegxz0OPZS/0mOehx7IXeszz0GOeh9CNdF3+5vfGG2+Yt99+25w5c8YYY8yQIUPMbbfdZt577z3nMvHx8ebJJ580a9euNYULFzb9+vW7rjXfKB544AFTqlQpM2nSJLNt2zYTFRVlxo4daw4cOGBmz55tHnroIVOiRAnn5R1iYmKMw+EwDz/8sPPDEO5Hj3kueix7oMc8Fz2WPdBjnose8zx+7j6RGzzT5WcnPHnypEaNGqWcOXOqc+fOat++vY4ePaqxY8dq3bp1uv3227VgwQJdvHhR1apVU7ly5XTixAk3VZ89GWPkcDi0aNEitW/fXu+8844ef/xxlS9fXh06dFCOHDlUrFgx3XzzzRo0aJCGDh2qyZMnq1SpUvr999+VkJAgf39/dz8N/D96zPPQY9kLPeZ56LHshR7zPPSYB3Nv5ocnutJ1EV999VXj4+NjxowZY4wx5tixY2b69OmmRo0a5u677zYtW7Y0Fy9eNMYY06RJE/PKK68YYxgylJVSj8sxxpjHH3/cBAQEmBIlSphTp065LDdp0iRTtGhRc/DgwetdIjKAHvNc9Fj2QI95Lnose6DHPBc95pkI3XBx6Zvoxo0bzerVq82qVauc06Kjo51vppee8OLSBu/Vq5cpUKCAyyUIkHUufa27dOliQkJCzIgRI1zeTH/99VcTERFhNm7c6I4ScRX0mOejx7wbPeb56DHvRo95PnrM8zC8HC58fHwkSdHR0VqyZIni4uKUP39+BQUFafXq1Ro6dKj8/PzUo0cP+fr66rHHHlNYWJh8fX21fft2ffLJJ1qyZIm++OILlSlTxs3PJnvy9fVVcnKyfH199cEHHyguLk4TJkxQcnKy2rVrp4CAAE2cOFEpKSkqVqyYu8vFZegxz0ePeTd6zPPRY96NHvN89JgHcnfqh+d55513TN68ec2GDRtMUlKSeeONN4zD4TDLly93LtOvXz/jcDjM/PnzXe771VdfmQMHDlzvkm9Il36L2a5dO5MzZ04TERFhHnnkEVOtWjWurejB6DHPkjqs8fLhjfSY96LH3C+94cL0WPZBj7nflYb4X4oe8xyEbrhISkoyTz31lBk/frwxxpiFCxea0NBQ5+3USw8YY8xHH33kHDbEsThZ5/I30UvfMC936bCt7t27G4fDYcaOHeu8/iI8Dz3mfqk9Fh8fbxISEszJkyed8y5/nekx70OPuV9qj50+fdocPnzY7Ny50zmPHvN+9Jj7pb6We/fuNWvWrLnqsvSYZyB03+AuD3iJiYmmevXq5uOPPzZffvmlyZUrl/nggw+MMf+8yb799ttm2rRpae6DrJG6PX799VczcuRI5/T0gnfqtEvndezY0ezbt89ukcgUesyzpG6PHTt2mIcffthUq1bN3H333Wlec2PoMW9Bj3mW1O3xyy+/mFq1apmoqCgTGhrq8pmWih7zDvSYZzp27JgJDAw0QUFBLiMMLkWPeQ4fdw9vh3ulHpezZMkSbdu2TX5+fqpZs6Y+/fRTtW7dWiNGjFCXLl0kSSdOnNA333yj2NhYl3X4+XFqgKxgjJGPj49iYmJ099136+WXX1Z0dLSk/x2bcylfX19J0vLly3Xo0CFJ0scff6zIyMjrWjeujh7zHKk9tmPHDt11110qUqSIHnroIVWsWFH9+vXT+vXrXZanx7wDPeY5UlJSXHqsVq1aGjp0qPr166c33njD2Uep6DHvQI95pjx58qhWrVqqUqWKmjdvri+//DLNMvSYB3F36of7/fbbb6ZMmTJm1KhRxhhjvvvuOxMaGmqqVavmHBL2559/miZNmpg777zzqsOd8d+cOXPGPPHEE6ZFixZm2LBhJjw83PTq1cs5//LXftWqVcbhcJghQ4awXTwYPeY5Tpw4YWrXrm1eeukl57R9+/aZatWqmQ8//NAY4zoEkh7zDvSY5/jzzz9NVFSU6du3r3PaL7/8Yho2bGh2795ttm7d6rI8PeYd6DHPkpSUZM6dO2fq1q1rvv/+e/P888+bXLlymZUrVxpjjMueb3rMMxC6b0DpnXhh6NChJiQkxMTExBhjjFmxYoUpUKCAue2220zp0qXNnXfeaapVq2YSEhKMMVc/zhjX7tSpU+bFF180CxcuNGfOnDEffPBBmuB9+fYbPXq02bFjx/UuFVdBj3mubdu2mUaNGpnVq1e7TG/Tpo3p0qWLMSbtaz9mzBh6zMPQY57r4MGDpmPHjuaXX35xTnv99ddNcHCwKV++vAkNDTWtWrVyOZ6UHvM89Jh3eOGFF8ysWbOMMf8MGw8NDTV169Y1tWvXNidOnHAuR4+5n8MYY9y9tx3uMXfuXIWFhal+/fqSpGbNmkmSpk6dqvDwcP3666/asWOH9u7dq1tvvVXNmjWTr6+vkpKSGCZk0alTpxQeHi5JOn36tGbOnKn+/furQ4cOGjFihCQpISFBf//9t3M5eCZ6zPMcP35cmzdvVpMmTSTJeUmVp556Sn5+fpowYYKbK0Rm0GOexRgjh8Oh2NhYhYWFSZI+/fRTde3aVR9//LGqVKmiCxcu6I477tBrr72mPn36uLli/Bt6zDOl9lqPHj105swZTZ48WZJUtmxZ/fbbb3r//ffVrVs353LwAG6N/HCbjRs3GofDYcqWLWs6depkkpOTzaJFi0yDBg3MzJkzr/jtJN9a2pE6nPXSE41cevbXMWPGuOzx7tKli+nVqxcnJvFg9JhnSe+suZfuyenWrZtp376983bv3r3NpEmTrkdpuEb0mGdJ7bHLX9/FixebjRs3ukxr2rSpefLJJ69bbbg29JhnSe2xSz+75s+f7xyl1aZNG1O4cGHz4IMPmvDwcLN48WK31In0cSK1G0RKSorL7YIFC6pVq1aqUqWKdu7cqZo1ayohIUHnzp3TzJkznSdeuNLJu5A1zD+HeMjhcGjdunX66KOPdPr0aUn/O3FJ7ty51aZNGw0ePFjTpk3Trbfeqo8++kitW7fmW2QPQo95pkt77LvvvtPYsWPT9JgkBQYGOrfFq6++qhEjRqhcuXJuqRnpo8c80+WfYx9++KGzxyTp/vvvV/Xq1Z23L1y4IIfDoSpVqrijXFwFPeaZLu+xcePGOXssMjJSP//8s+rXr6/ly5dr6dKlWrBgge69914999xziouLc3P1SEXovkGk/nO5evVqSVJERISaN2+un376SXPnzlWrVq20YsUKhYSEaMmSJRowYIAk3jhtOXfunCTJ4XDI4XBo3rx5atq0qY4cOaL9+/enWT4sLEwPP/ywIiMjdfz4cW3fvl3VqlW7zlXjaugxz5JejzVr1ixNj5n/P8Lq3LlzCgkJ0ahRo/T2229r8+bNqlGjhjtKxxXQY54ls59jqYYMGaKff/5ZzZs3v06VIqPoMc9ytR7bt2+fpH/OYB4fH69jx45p2bJlqly5siRpzpw5+uGHHxQcHOyu8nE5t+1jx3W3ceNGU6RIEVOnTh2zZ88eY4wx3bt3N3Xr1jUJCQlm+/bt5p133jEOh8M0btw43eGY+O+eeeYZ06FDB+fwq02bNpmbbrrJeebk9CQlJZlXX33V+Pr6mu3bt1+vUpFJ9JhnyEyPpW6D559/3jgcDhMWFmY2bdp0XetFxtFjnuFaPsdWr15tnn76aZMvX740ZzCH56DHPENmeuzLL780u3fvvt4lIpMYm3oDueWWW7Rs2TJ1795dLVu2VPPmzfXQQw/J4XBo8uTJevrppxUVFaW7775blSpVksPh4AQMWWzWrFlauHChvv76a+c3wz///LNuvvlmtWvXzrlc6rVOU509e1Z///23tm7dqqioqOteNzKGHnO/zPZY6mtfsmRJ5c+fXytWrFCFChXcUjv+HT3mftfyOXbhwgUdOXJEp0+f1urVq1W+fHm31I5/R4+5X0Z7LDExUf7+/mrYsKEksR08HMPLbyAhISGKiorSmjVr9OSTT+qXX37Ro48+qk2bNmnVqlW6cOGCJOm2225znnmS5s1ahw4dUt68eVW5cmUtWrRIo0aN0pkzZ3T27FmXY6lS/1H59ttvderUKeXJk0cjR44kcHs4esz9rqXHYmNj1bp1a23bto3A7eHoMffLbI999913SkhI0KOPPqopU6YQuD0cPeZ+Ge0xf39/Sf98jp0+fZrt4OEI3TeY1JNd9O7dWyNHjlT37t21adMmzZo1S1OnTnVZlpN0Zb177rlHxhjde++9atGihSIjI1W8eHHt3LlTGzZscFk2OTlZn332mRYuXChjDMdMeShz2VUX6TH3ymyPzZkzRwsWLFDBggVVsGBBN1WNq6HHPEtme2z27NmaN2+ejDEcX+ol6DH3+i//K8KDuWNMO+y72uUaLj/+Zs2aNaZ3795cfuo66dq1q3E4HOaOO+5wTnvkkUdM3rx5zVdffWX++usvc/r0adO3b19ToEABExMT48ZqcbmjR4+aEydOmEOHDjmnXd5T9Jh70WPebffu3Wb79u1mw4YNzmn0mGehx7zbkiVLzFdffXXVZegx96LHsh+HMXwtkl3MmDFDu3bt0qBBgyT98+3X5XtHU6eZKxz3kZSUxLeWFp0/f17NmjVTyZIltX79elWqVEkzZsxQQkKCnn32Wc2aNUtFixZV7ty5deTIEX3++edcVsWDTJ8+XRMmTNCBAwcUHh6u7t27q3379i7L0GPuRY95t6lTp2r48OFKSkrS/v37NWzYMPXs2dNlGXrMvegx77Z161ZVq1ZNYWFhmjNnjurXr59mGXrMveix7InQnU0sWrRILVu2lDFGvXv31ptvvikp/eD9119/admyZapfv74KFSrkjnJvaPHx8cqZM6cmTpyo4cOHq0aNGpo2bZokadmyZfrrr7/k7++vWrVqqVixYm6uFqmmTZumzp07a9SoUfLz89OuXbu0cOFCzZkzR5UqVXJZlh5zL3rMO02bNk2dOnXSxx9/rDJlymjFihX6+OOPtW3bNoWEhLgsS4+5Fz3mvU6ePKknnnhCAQEBWrFihebPn69GjRqlWY4ecy96LBty2z52ZJmYmBjTuHFj88ILL5h3333XhIeHm169ejnnXz7UfN68ecbhcJjx48df71JxiXPnzpmJEyeasmXLmscee8zd5eAqtm/fbipWrGgmT57snLZjxw5TqlQpM3/+/DTL02OegR7zHt99950pUaKEmTFjhnPaypUrTfPmzc26devM119/7TKsde7cufSYB6DHvEtKSoo5fPiwqVKlitm1a5fp1KmTyZUrl1m/fr0xxrj0H59jnoEeyz4I3dnA8ePHTe/evc2mTZtMXFycGTt2bJrgnZyc7HKfGTNmcFyOB/j777/NxIkTTYUKFcz999/v7nJwBWvXrjUPPPCA+fXXX12mN2jQwAwbNswYk/bLrZkzZ9JjHoAe8w779u0zvXv3Nn/88YdzWuPGjU2+fPlM5cqVTXBwsHnooYfMqVOnnPPpMc9Aj3mftm3bOs+Z0LlzZ5MrVy5TrFgx8+STT5oLFy44l6PHPAM9lj0wvDybOHv2rEJDQyVJp0+f1syZM9W/f3916NBBI0aMkCSdOXNGFy9eVIECBZz347gc94uLi9PUqVM1efJkLViwQIULF3Z3SbjMkSNHdOjQIdWoUUPS/w7baNCggWrXrq3+/ftf8b70mPvRY57N/P9xo3Fxcc6zW/fv31+fffaZ5syZo8jISB05ckSVKlXSqFGj1LlzZ5f702PuR495h9Ree/TRR1W8eHENHz5ciYmJKly4sE6fPq0ZM2aoVatWaY7lpsfcjx7zfoRuL5WSkuK8BmZCQoICAgKclwpwOBw6c+aMpk+frtdee01PP/20hgwZorvuukvNmzdXdHS0O0tHOuLj45WYmKiwsDB3l4L/d2mPXfq7+WeEkHx8fNSkSRNVr15dAwcOlDFGdevWVbdu3fTwww+7s3Skgx7zPOl9jqVavny5oqKiXL4krl69upo3b65+/fpd91rx7+gxz3NpjyUmJjqv6/zuu+8qPj5er776qqKiohQeHq6iRYtq6dKlmjx5spo3b+7OsnEF9Jh34zrdXig5Odn5Jvrxxx/r/fff15kzZ+RwOJzfTObOnVtt2rTRkCFDNHHiRN100006fvy4evXq5c7ScQU5c+bkTdSDXNpjEyZM0Ntvv60zZ85I+udLrdR5QUFBzhMVNmnSRPv27eOfFQ9Fj3mWK32Opapfv75L4D527JgCAgJ08803X+9SkUH0mGe5vMfee+89Z49VqlRJixcvVmRkpEJDQzVv3jx9+umnqlevnsaMGePGqnE19Jh3I3R7kZMnT0qS85/83r1767XXXlNISIhiY2PTLB8WFqZ69erJ399f5cuX1549e+Tv76+kpKTrWjfgLdLrsQEDBig0NNSlxy4dIJSYmKjHHntMMTExiomJoceAq8js55gxRnFxcerYsaN8fHz00EMPXdd6AW9ztR5LDd033XST/v77b1WvXl3z589X3rx5JUnz5s3TV1995Za6geyOAzS8RFRUlJo2baphw4ZJkmbOnKnp06dr/vz5uuOOO9K9z7lz5/Tyyy8rODhYq1evlp+fH8flAFeQmR5LPd7twoULGjJkiCpVqqRff/3VGbjpMSCtzH6OJSQkaOHChRo3bpxiY2P1ww8/yNfXN91LYQLIeI9VrFhR48eP16233qrw8HCXdfj4+LgMSweQNegoLzBo0CA5HA4NGTLEOW337t267bbbXN5ELz88//z586pWrZp27txJ4AauIrM9lnoYR40aNXT33Xdr06ZNBG7gKq7lcyw5OVnJycmKiorSxo0bnT1G4AbSymiPpY7EqlWrlsLDw9P87yiJwA1YwH+HXiA2NlZ+fn7y8fFRr169FBERoTNnzighIcFlOYfDoaSkJC1btky1atVS/vz5nWdVTk5OJgwAV3AtPXbPPfeoS5cu6t+/v3x8fAjcwFVktse++OIL3X333Xrsscf02GOPSeJzDLiajPZY6k6YZcuWqXbt2sqTJ4+bKgZuLHyV5cFSv31s0aKFzp8/r0qVKmnChAlq1aqVKlWqpJUrV+rbb791uc/Zs2c1bdq0NNPZMwCkda09NmXKFK1evVr58+eXj4+PjDGEASAd/6XHVq1a5TKdzzEgrf/yv+LatWvdUTJwQ+KSYV6iUaNG+vrrr9WoUSMtW7ZMkvTwww9r1apVmjRpksqWLStfX19169ZNJ0+e1IYNG/gHBcgEegywix4D7KLHAM9F6PYCp06dUrt27VSjRg3NmjVLlSpV0owZM5ScnKxOnTrps88+U2BgoAoUKKCQkBCtWbNG/v7+nGwGyCB6DLCLHgPsoscAz0bo9hKp11ucNGmShg8frho1amjatGmSpHXr1unChQvy9fVVnTp1OL4UuAb0GGAXPQbYRY8BnovQ7WXi4uI0Z84cDR8+XLfddptmzJiRZhm+tQSuHT0G2EWPAXbRY4DnIXR7obi4OH322WcaOXKkihcvrqVLl7q7JCBboccAu+gxwC56DPAsjCnxQsHBwXrkkUcUFxendevWKSUlhWsqAlmIHgPsoscAu+gxwLOwp9uLXbhwQYGBgXI4HLyZAhbQY4Bd9BhgFz0GeAZCdzZgjJHD4XB3GUC2RY8BdtFjgF30GOBehG4AAAAAACxhjAkAAAAAAJYQugEAAAAAsITQDQAAAACAJYRuAAAAAAAsIXQDAAAAAGAJoRsAAAAAAEsI3QAAAAAAWELoBgAAAADAEkI3AAAAAACWELoBAAAAALDk/wBjJzIGdoFBvgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "       super(Model, self).__init__()\n",
    "       self.fc1 = nn.Linear(201, 150)\n",
    "       self.fc2 = nn.Linear(150, 100)\n",
    "       self.fc3 = nn.Linear(100, 50)\n",
    "       self.fc4 = nn.Linear(50, 1)\n",
    "       self.relu = nn.ReLU()\n",
    "       \n",
    "       # Initialize weights using He initialization for each linear layer\n",
    "       init.kaiming_normal_(self.fc1.weight, mode='fan_in', nonlinearity='relu')\n",
    "       init.kaiming_normal_(self.fc2.weight, mode='fan_in', nonlinearity='relu')\n",
    "       init.kaiming_normal_(self.fc3.weight, mode='fan_in', nonlinearity='relu')\n",
    "       init.kaiming_normal_(self.fc4.weight, mode='fan_in', nonlinearity='relu')\n",
    "\n",
    "    def forward(self, x):\n",
    "        #x = x.view(x.size(0), -1)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.relu(self.fc3(x))\n",
    "        x = torch.exp(self.fc4(x)) # ensures all values are positive\n",
    "        return x\n",
    "\n",
    "# input size: [16, 12, 200]\n",
    "model = Model()\n",
    "print(model)\n",
    "\n",
    "arr = torch.randn((16, 201))#12,200))\n",
    "print(model(arr).shape)\n",
    "nparm = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"Number of parameters: \" + str(nparm))\n",
    "\n",
    "output = model(arr)\n",
    "\n",
    "# Compute gradients\n",
    "output.mean().backward()\n",
    "\n",
    "# Plot gradients\n",
    "gradient_list = []\n",
    "parameter_names = []\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    if param.grad is not None:\n",
    "        gradient_list.append(param.grad.norm().item())\n",
    "        parameter_names.append(name)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(parameter_names, gradient_list)\n",
    "plt.ylabel('Gradient Norm')\n",
    "plt.title('Gradients of Model Parameters')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f03d0d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class CustomLoss_1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomLoss_1, self).__init__()\n",
    "\n",
    "    def forward(self, X_ji, C_j, Z_ji):\n",
    "        #print(Z_ji)\n",
    "        epsilon = 1e-8\n",
    "        clipped_Z_ji = torch.clamp(Z_ji, epsilon)\n",
    "        loss = X_ji * torch.log(clipped_Z_ji) + C_j * torch.exp(-clipped_Z_ji)\n",
    "        # compute mean over batch to normalize due to varying batch sizes\n",
    "        return (loss).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b67229",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KernelDensity\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CustomLoss_2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomLoss_2, self).__init__()\n",
    "\n",
    "    def forward(self, X_ji, C_j, Z_ji):\n",
    "        #print(Z_ji)\n",
    "        epsilon = 1e-8\n",
    "        Z_ji = torch.clamp(Z_ji, epsilon)\n",
    "        flat_Z_ji = Z_ji.view(-1)\n",
    "        min_value = torch.min(flat_Z_ji)\n",
    "        max_value = torch.max(flat_Z_ji)\n",
    "        uniform_distribution = torch.ones_like(Z_ji) / (max_value - min_value)\n",
    "        kde_Z_ji = torch.zeros_like(Z_ji, dtype=torch.float32)\n",
    "        kde = KernelDensity(kernel='gaussian', bandwidth=\"silverman\")#0.5)\n",
    "        for i in range(Z_ji.shape[0]):\n",
    "            sample = Z_ji[i].detach().numpy().reshape(-1, 1)  # Reshape to (200, 1)\n",
    "            kde.fit(sample)\n",
    "            kde_estimates = torch.exp(torch.tensor(kde.score_samples(sample), dtype=torch.float32))\n",
    "            kde_Z_ji[i] = kde_estimates.squeeze()\n",
    "            \n",
    "        #kde = KernelDensity(kernel='gaussian', bandwidth=0.5)\n",
    "        #kde.fit((Z_ji).detach().numpy())\n",
    "        #kde_Z_ji = torch.exp(torch.tensor(kde.score_samples(Z_ji.detach().numpy()), dtype=torch.float32))\n",
    "        weights = uniform_distribution / kde_Z_ji.unsqueeze(1)\n",
    "        loss = X_ji * torch.log(Z_ji) + C_j * torch.exp(-Z_ji)\n",
    "        # compute mean over batch to normalize due to varying batch sizes\n",
    "        return (weights*loss).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "32c52119",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KernelDensity\n",
    "\n",
    "class CustomLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomLoss, self).__init__()\n",
    "\n",
    "    def forward(self, X_ji, C_j, Z_ji):\n",
    "        epsilon = 1e-8\n",
    "        #print(\"Z_ji\")\n",
    "        #print(Z_ji)\n",
    "        #kde = KernelDensity(kernel='gaussian', bandwidth=0.5)#bandwidth=\"silverman\")\n",
    "        #kde.fit((Z_ji).detach().numpy())\n",
    "        #kde_Z_ji = torch.exp(torch.tensor(kde.score_samples(Z_ji.detach().numpy()), dtype=torch.float32))\n",
    "        kde_X_ji = torch.zeros_like(X_ji, dtype=torch.float32)\n",
    "        kde = KernelDensity(kernel='gaussian', bandwidth=0.5)#\"silverman\")\n",
    "        for i in range(X_ji.shape[0]):\n",
    "            sample = X_ji[i].detach().numpy().reshape(-1, 1)  # Reshape to (200, 1)\n",
    "            kde.fit(sample)\n",
    "            kde_estimates = torch.exp(torch.tensor(kde.score_samples(sample), dtype=torch.float32))\n",
    "            kde_X_ji[i] = kde_estimates.squeeze()\n",
    "        min_value = torch.min(kde_X_ji)\n",
    "        max_value = torch.max(kde_X_ji)\n",
    "\n",
    "        # Normalize the KDE values to the range [0, 1]\n",
    "        normalized_kde_values = (kde_X_ji - min_value) / (max_value - min_value)\n",
    "        weights = 1 - (0.9 * normalized_kde_values)\n",
    "        weights = torch.clamp(weights, epsilon)\n",
    "        weights_sum = torch.sum(weights)\n",
    "        normalized_weights = weights / weights_sum\n",
    "        epsilon = 1e-8\n",
    "        Z_ji = torch.clamp(Z_ji, epsilon)\n",
    "        loss = X_ji * torch.log(Z_ji) + C_j * torch.exp(-Z_ji)\n",
    "        #print(\"loss\")\n",
    "        #print(loss)\n",
    "        #print(\"weights\")\n",
    "        #print(normalized_weights)\n",
    "        # compute mean over batch to normalize due to varying batch sizes\n",
    "        return (normalized_weights*loss).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "422082b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(targets, outputs):\n",
    "    indices = range(len(targets[0]))\n",
    "\n",
    "    fig, axs = plt.subplots(3, 3, figsize=(15,15))\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            axs[i, j].scatter(indices, targets[i+j*3], s=5)\n",
    "            axs[i, j].scatter(indices, outputs.detach().numpy()[i+j*3], s=5)\n",
    "            axs[i, j].set_ylim(-0.25, 1.3)\n",
    "\n",
    "    plt.xlabel('Index')\n",
    "    plt.ylabel('Elongation Rates')\n",
    "    plt.legend(['GLM Elongation Rate', 'NN Elongation Rate'], loc='upper center', bbox_to_anchor=(0.5, -0.6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6c28ed03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [28000] at entry 0 and [39620] at entry 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m     18\u001b[0m model\u001b[39m.\u001b[39mtrain()\n\u001b[0;32m---> 19\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m trndl:\n\u001b[1;32m     20\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     21\u001b[0m     \u001b[39m#Y_ji_batch = batch['Y_ji']\u001b[39;00m\n",
      "File \u001b[0;32m~/software/anaconda3/envs/cnn-motif/lib/python3.8/site-packages/torch/utils/data/dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    632\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    634\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    635\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    636\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/software/anaconda3/envs/cnn-motif/lib/python3.8/site-packages/torch/utils/data/dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    676\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 677\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    678\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    679\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/software/anaconda3/envs/cnn-motif/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 54\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollate_fn(data)\n",
      "File \u001b[0;32m~/software/anaconda3/envs/cnn-motif/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py:265\u001b[0m, in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdefault_collate\u001b[39m(batch):\n\u001b[1;32m    205\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[39m        Function that takes in a batch of data and puts the elements within the batch\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \u001b[39m        into a tensor with an additional outer dimension - batch size. The exact output type can be\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[39m            >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 265\u001b[0m     \u001b[39mreturn\u001b[39;00m collate(batch, collate_fn_map\u001b[39m=\u001b[39;49mdefault_collate_fn_map)\n",
      "File \u001b[0;32m~/software/anaconda3/envs/cnn-motif/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py:127\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, collections\u001b[39m.\u001b[39mabc\u001b[39m.\u001b[39mMapping):\n\u001b[1;32m    126\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 127\u001b[0m         \u001b[39mreturn\u001b[39;00m elem_type({key: collate([d[key] \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m batch], collate_fn_map\u001b[39m=\u001b[39mcollate_fn_map) \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m elem})\n\u001b[1;32m    128\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m         \u001b[39m# The mapping type may not support `__init__(iterable)`.\u001b[39;00m\n\u001b[1;32m    130\u001b[0m         \u001b[39mreturn\u001b[39;00m {key: collate([d[key] \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m batch], collate_fn_map\u001b[39m=\u001b[39mcollate_fn_map) \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m elem}\n",
      "File \u001b[0;32m~/software/anaconda3/envs/cnn-motif/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py:127\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, collections\u001b[39m.\u001b[39mabc\u001b[39m.\u001b[39mMapping):\n\u001b[1;32m    126\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 127\u001b[0m         \u001b[39mreturn\u001b[39;00m elem_type({key: collate([d[key] \u001b[39mfor\u001b[39;49;00m d \u001b[39min\u001b[39;49;00m batch], collate_fn_map\u001b[39m=\u001b[39;49mcollate_fn_map) \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m elem})\n\u001b[1;32m    128\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m         \u001b[39m# The mapping type may not support `__init__(iterable)`.\u001b[39;00m\n\u001b[1;32m    130\u001b[0m         \u001b[39mreturn\u001b[39;00m {key: collate([d[key] \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m batch], collate_fn_map\u001b[39m=\u001b[39mcollate_fn_map) \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m elem}\n",
      "File \u001b[0;32m~/software/anaconda3/envs/cnn-motif/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py:119\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[39mif\u001b[39;00m collate_fn_map \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    118\u001b[0m     \u001b[39mif\u001b[39;00m elem_type \u001b[39min\u001b[39;00m collate_fn_map:\n\u001b[0;32m--> 119\u001b[0m         \u001b[39mreturn\u001b[39;00m collate_fn_map[elem_type](batch, collate_fn_map\u001b[39m=\u001b[39;49mcollate_fn_map)\n\u001b[1;32m    121\u001b[0m     \u001b[39mfor\u001b[39;00m collate_type \u001b[39min\u001b[39;00m collate_fn_map:\n\u001b[1;32m    122\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, collate_type):\n",
      "File \u001b[0;32m~/software/anaconda3/envs/cnn-motif/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py:162\u001b[0m, in \u001b[0;36mcollate_tensor_fn\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    160\u001b[0m     storage \u001b[39m=\u001b[39m elem\u001b[39m.\u001b[39m_typed_storage()\u001b[39m.\u001b[39m_new_shared(numel, device\u001b[39m=\u001b[39melem\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m    161\u001b[0m     out \u001b[39m=\u001b[39m elem\u001b[39m.\u001b[39mnew(storage)\u001b[39m.\u001b[39mresize_(\u001b[39mlen\u001b[39m(batch), \u001b[39m*\u001b[39m\u001b[39mlist\u001b[39m(elem\u001b[39m.\u001b[39msize()))\n\u001b[0;32m--> 162\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mstack(batch, \u001b[39m0\u001b[39;49m, out\u001b[39m=\u001b[39;49mout)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [28000] at entry 0 and [39620] at entry 1"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n",
    "\n",
    "\n",
    "num_epochs = 50\n",
    "\n",
    "loss_hist_train = [0] * num_epochs\n",
    "loss_hist_valid = [0] * num_epochs\n",
    "\n",
    "loss_fn = CustomLoss_1()#nn.L1Loss()#nn.MSELoss()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'Epoch {epoch+1}')\n",
    "    model.train()\n",
    "    for batch in trndl:\n",
    "        optimizer.zero_grad()\n",
    "        #Y_ji_batch = batch['Y_ji']\n",
    "        X_ji_batch = batch['X_ji']\n",
    "        C_j_batch = batch['C_j']\n",
    "        outputs = model(X_ji_batch)\n",
    "        loss = loss_fn(X_ji_batch, C_j_batch, outputs)\n",
    "        #loss = loss_fn(batch['Z_ji'], outputs)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_hist_train[epoch] += loss.item()\n",
    "        #if epoch == 49:\n",
    "         #   plot_data(batch['Z_ji'], outputs)\n",
    "    loss_hist_train[epoch] /= len(trndl.dataset)\n",
    "    scheduler.step()\n",
    "    \n",
    "    #model.eval()\n",
    "    #with torch.no_grad():\n",
    "    #    for batch in valdl:\n",
    "    #        Y_ji_batch = batch['Y_ji']\n",
    "    #        X_ji_batch = batch['X_ji']\n",
    "    #        C_j_batch = batch['C_j']\n",
    "    #        outputs = model(Y_ji_batch)\n",
    "    #        loss = loss_fn(X_ji_batch, C_j_batch, outputs)\n",
    "            #loss = loss_fn(batch['Z_ji'], outputs)\n",
    "    #        loss_hist_valid[epoch] += loss.item()\n",
    "    #    loss_hist_valid[epoch] /= len(valdl.dataset)\n",
    "    \n",
    "    print(f'Epoch {epoch+1} trn_loss: '\n",
    "          f'{loss_hist_train[epoch]:.4f}')# val_loss: '\n",
    "          #f'{loss_hist_valid[epoch]:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94841213",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "epochs = range(1, len(loss_hist_train) + 1)\n",
    "plt.plot(epochs, loss_hist_train, label='train_loss')\n",
    "plt.plot(epochs, loss_hist_valid, label='valid_loss')\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7239c5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "inputs = next(iter(trndl))#tstdl)) \n",
    "print(\"number of samples: \" + str(len(inputs)))\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(inputs['Y_ji'])\n",
    "    \n",
    "#outputs = torch.exp(outputs)\n",
    "print(outputs)\n",
    "\n",
    "targets = inputs['Z_ji']\n",
    "\n",
    "plot_data(targets, outputs)\n",
    "\n",
    "#for batch in trndl:\n",
    "#    targets = inputs['Z_ji']\n",
    "#    outputs = model(inputs['X_ji'])#'Y_ji'])\n",
    "#    outputs = torch.exp(outputs)\n",
    "    \n",
    "#    plot_data(targets, outputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
