{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35ba1335",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.utils.data as td\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "froot = './data/k562_main'\n",
    "\n",
    "df = pd.read_csv(froot + \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25c67eaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   seqnames    start      end strand  ensembl_gene_id  score      ctcf  \\\n",
      "0         1  3859709  3859709      +  ENSG00000169598    0.0 -0.010876   \n",
      "1         1  3859710  3859710      +  ENSG00000169598    0.0 -0.010887   \n",
      "2         1  3859711  3859711      +  ENSG00000169598    0.0 -0.010902   \n",
      "3         1  3859712  3859712      +  ENSG00000169598    0.0 -0.010920   \n",
      "4         1  3859713  3859713      +  ENSG00000169598    0.0 -0.010941   \n",
      "\n",
      "   h3k36me3   h3k4me1  h3k79me2  ...       sj3       dms      rpts  wgbs  \\\n",
      "0  0.353765 -0.078256 -0.156547  ... -0.057178 -0.307549  0.249626   0.0   \n",
      "1  0.347003 -0.077117 -0.155891  ... -0.057178 -0.307549  0.249626   0.0   \n",
      "2  0.340295 -0.075994 -0.155236  ... -0.057178 -0.307549  0.249626   0.0   \n",
      "3  0.333641 -0.074887 -0.154583  ... -0.057178 -0.307549  0.249626   0.0   \n",
      "4  0.327043 -0.073795 -0.153930  ... -0.057178 -0.307549  0.249626   0.0   \n",
      "\n",
      "       A         T         G         C  lambda_alphaj      zeta  \n",
      "0 -0.625 -0.678443  1.954571 -0.494439       0.014335  0.932859  \n",
      "1 -0.625 -0.678443  1.954571 -0.494439       0.014335  0.933402  \n",
      "2 -0.625  1.473964 -0.511621 -0.494439       0.014335  0.933944  \n",
      "3 -0.625  1.473964 -0.511621 -0.494439       0.014335  0.934485  \n",
      "4 -0.625 -0.678443  1.954571 -0.494439       0.014335  0.935024  \n",
      "\n",
      "[5 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b54d1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['gene_length'] = df.groupby('ensembl_gene_id')['ensembl_gene_id'].transform('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a8abcdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ctcf', 'h3k36me3', 'h3k4me1', 'h3k79me2', 'h3k9me1', 'h3k9me3', 'h4k20me1', 'sj5', 'sj3', 'dms', 'rpts', 'wgbs']\n",
      "['A', 'T', 'G', 'C']\n"
     ]
    }
   ],
   "source": [
    "column_names = df.columns.tolist()\n",
    "feature_names = column_names[6:-7]\n",
    "nucleotides = column_names[-7:-3]\n",
    "print(feature_names)\n",
    "print(nucleotides)\n",
    "\n",
    "# process read counts\n",
    "X_ji = df.groupby('ensembl_gene_id')['score'].apply(list).tolist() \n",
    "\n",
    "# process GLM simulated elongation rates\n",
    "Z_ji = df.groupby('ensembl_gene_id')['zeta'].apply(list).tolist() \n",
    "\n",
    "num_samples = len(X_ji)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40cae20e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1502\n"
     ]
    }
   ],
   "source": [
    "print(num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef3e2763",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window(data, window_size):\n",
    "    data = np.array(data)  # Convert data to a NumPy array for efficient operations\n",
    "    num_sites = len(data)\n",
    "    \n",
    "    sub_sequences = []\n",
    "    \n",
    "    for i in range(num_sites):\n",
    "        start = i - window_size // 2\n",
    "        end = i + window_size // 2 + 1  # +1 to include the right edge\n",
    "        \n",
    "        # Ensure that the window is within the bounds of the sequence\n",
    "        if start < 0:\n",
    "            padding_start = abs(start)\n",
    "            start = 0\n",
    "        else:\n",
    "            padding_start = 0\n",
    "        \n",
    "        if end > num_sites:\n",
    "            padding_end = end - num_sites\n",
    "            end = num_sites\n",
    "        else:\n",
    "            padding_end = 0\n",
    "        \n",
    "        window = data[start:end]\n",
    "        \n",
    "        # Pad the window if necessary\n",
    "        if padding_start > 0 or padding_end > 0:\n",
    "            window = np.pad(window, (padding_start, padding_end), mode='constant')\n",
    "        \n",
    "        sub_sequences.append(window)\n",
    "    \n",
    "    return sub_sequences\n",
    "\n",
    "window_size = 201  # 100 sites to the left, 100 sites to the right, and the target site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ecb3e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ji_windows = []\n",
    "for seq in X_ji:\n",
    "    x_windows = sliding_window(seq, window_size)\n",
    "    X_ji_windows.extend(x_windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f77d389",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_ji_windows = []\n",
    "for seq in Z_ji:\n",
    "    z_windows = sliding_window(seq, window_size)\n",
    "    Z_ji_windows.extend(z_windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cffd98a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "C_j = df.groupby('ensembl_gene_id')['lambda_alphaj'].apply(list).tolist() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "195a1625",
   "metadata": {},
   "outputs": [],
   "source": [
    "C_j_windows = []\n",
    "for seq in C_j:\n",
    "    c_windows = sliding_window(seq, window_size)\n",
    "    C_j_windows.extend(c_windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e396e7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#Y_ji is a list of samples containing lists of their feature values\n",
    "    # [   \n",
    "    #   [[sample_1_feature_1], [sample_1_feature_2], [sample_1_feature_3]],\n",
    "    #   [[sample_2_feature_1], [sample_2_feature_2], [sample_2_feature_3]],  \n",
    "    # ]\n",
    "\n",
    "Y_ji = []\n",
    "\n",
    "for sample_id in df['ensembl_gene_id'].unique():\n",
    "    sample_data = [df[feature_name][df['ensembl_gene_id'] == sample_id].tolist() for feature_name in feature_names]\n",
    "    Y_ji.append(sample_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c660a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize features\n",
    "scaler = MinMaxScaler()\n",
    "Y_ji = np.array(Y_ji)\n",
    "# reshape dataset to [num_samples, num_features * feature_length]\n",
    "Y_ji_reshaped = Y_ji.reshape(Y_ji.shape[0], -1)\n",
    "normalized_Y_ji_reshaped = scaler.fit_transform(Y_ji_reshaped)\n",
    "Y_ji = normalized_Y_ji_reshaped.reshape(Y_ji.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35f18812",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, X_ji, C_j, Z_ji):\n",
    "        #self.Y_ji = Y_ji\n",
    "        self.X_ji = X_ji\n",
    "        self.C_j = C_j\n",
    "        self.Z_ji = Z_ji\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X_ji)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            #'Y_ji':  torch.tensor(self.Y_ji[idx], dtype=torch.float32),\n",
    "            'X_ji': torch.tensor(self.X_ji[idx], dtype=torch.float32),\n",
    "            'C_j': torch.tensor(self.C_j[idx], dtype=torch.float32),\n",
    "            'Z_ji': torch.tensor(self.Z_ji[idx], dtype=torch.float32)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5977e736",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CustomDataset(X_ji_windows, C_j_windows, Z_ji_windows)\n",
    "\n",
    "trnset, valset, tstset = td.random_split(dataset, [0.9,0,0.1])\n",
    "\n",
    "trndl = DataLoader(trnset, batch_size=128, shuffle=True)\n",
    "tstdl = DataLoader(tstset, batch_size=128, shuffle=False)\n",
    "valdl = DataLoader(valset, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2404f7d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (fc1): Linear(in_features=201, out_features=150, bias=True)\n",
      "  (fc2): Linear(in_features=150, out_features=100, bias=True)\n",
      "  (fc3): Linear(in_features=100, out_features=50, bias=True)\n",
      "  (fc4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  (relu): ReLU()\n",
      ")\n",
      "torch.Size([128, 1])\n",
      "Number of parameters: 50501\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "       super(Model, self).__init__()\n",
    "       self.fc1 = nn.Linear(201, 150)\n",
    "       self.fc2 = nn.Linear(150, 100)\n",
    "       self.fc3 = nn.Linear(100, 50)\n",
    "       self.fc4 = nn.Linear(50, 1)\n",
    "       self.relu = nn.ReLU()\n",
    "       \n",
    "       # Initialize weights using He initialization for each linear layer\n",
    "       #init.kaiming_normal_(self.fc1.weight, mode='fan_in', nonlinearity='relu')\n",
    "       #init.kaiming_normal_(self.fc2.weight, mode='fan_in', nonlinearity='relu')\n",
    "       #init.kaiming_normal_(self.fc3.weight, mode='fan_in', nonlinearity='relu')\n",
    "       #init.kaiming_normal_(self.fc4.weight, mode='fan_in', nonlinearity='relu')\n",
    "\n",
    "    def forward(self, x):\n",
    "        #x = x.view(x.size(0), -1)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.relu(self.fc3(x))\n",
    "        x = torch.exp(self.fc4(x)) # ensures all values are positive\n",
    "        return x\n",
    "\n",
    "# input size: [128, 12, 200]\n",
    "model = Model()\n",
    "print(model)\n",
    "\n",
    "arr = torch.randn((128, 201))#12,200))\n",
    "print(model(arr).shape)\n",
    "nparm = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"Number of parameters: \" + str(nparm))\n",
    "\n",
    "output = model(arr)\n",
    "\n",
    "# Compute gradients\n",
    "output.mean().backward()\n",
    "\n",
    "# Plot gradients\n",
    "gradient_list = []\n",
    "parameter_names = []\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    if param.grad is not None:\n",
    "        gradient_list.append(param.grad.norm().item())\n",
    "        parameter_names.append(name)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(parameter_names, gradient_list)\n",
    "plt.ylabel('Gradient Norm')\n",
    "plt.title('Gradients of Model Parameters')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f03d0d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class CustomLoss_1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomLoss_1, self).__init__()\n",
    "\n",
    "    def forward(self, X_ji, C_j, Z_ji):\n",
    "        #print(Z_ji)\n",
    "        epsilon = 1e-8\n",
    "        clipped_Z_ji = torch.clamp(Z_ji, epsilon)\n",
    "        loss = X_ji * torch.log(clipped_Z_ji) + C_j * torch.exp(-clipped_Z_ji)\n",
    "        # compute mean over batch to normalize due to varying batch sizes\n",
    "        return (loss).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9b67229",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KernelDensity\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CustomLoss_2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomLoss_2, self).__init__()\n",
    "\n",
    "    def forward(self, X_ji, C_j, Z_ji):\n",
    "        #print(Z_ji)\n",
    "        epsilon = 1e-8\n",
    "        Z_ji = torch.clamp(Z_ji, epsilon)\n",
    "        flat_Z_ji = Z_ji.view(-1)\n",
    "        min_value = torch.min(flat_Z_ji)\n",
    "        max_value = torch.max(flat_Z_ji)\n",
    "        uniform_distribution = torch.ones_like(Z_ji) / (max_value - min_value)\n",
    "        kde_Z_ji = torch.zeros_like(Z_ji, dtype=torch.float32)\n",
    "        kde = KernelDensity(kernel='gaussian', bandwidth=\"silverman\")#0.5)\n",
    "        for i in range(Z_ji.shape[0]):\n",
    "            sample = Z_ji[i].detach().numpy().reshape(-1, 1)  # Reshape to (200, 1)\n",
    "            kde.fit(sample)\n",
    "            kde_estimates = torch.exp(torch.tensor(kde.score_samples(sample), dtype=torch.float32))\n",
    "            kde_Z_ji[i] = kde_estimates.squeeze()\n",
    "            \n",
    "        #kde = KernelDensity(kernel='gaussian', bandwidth=0.5)\n",
    "        #kde.fit((Z_ji).detach().numpy())\n",
    "        #kde_Z_ji = torch.exp(torch.tensor(kde.score_samples(Z_ji.detach().numpy()), dtype=torch.float32))\n",
    "        weights = uniform_distribution / kde_Z_ji.unsqueeze(1)\n",
    "        loss = X_ji * torch.log(Z_ji) + C_j * torch.exp(-Z_ji)\n",
    "        # compute mean over batch to normalize due to varying batch sizes\n",
    "        return (weights*loss).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "32c52119",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KernelDensity\n",
    "\n",
    "class CustomLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomLoss, self).__init__()\n",
    "\n",
    "    def forward(self, X_ji, C_j, Z_ji):\n",
    "        epsilon = 1e-8\n",
    "        #print(\"Z_ji\")\n",
    "        #print(Z_ji)\n",
    "        #kde = KernelDensity(kernel='gaussian', bandwidth=0.5)#bandwidth=\"silverman\")\n",
    "        #kde.fit((Z_ji).detach().numpy())\n",
    "        #kde_Z_ji = torch.exp(torch.tensor(kde.score_samples(Z_ji.detach().numpy()), dtype=torch.float32))\n",
    "        kde_X_ji = torch.zeros_like(X_ji, dtype=torch.float32)\n",
    "        kde = KernelDensity(kernel='gaussian', bandwidth=0.5)#\"silverman\")\n",
    "        for i in range(X_ji.shape[0]):\n",
    "            sample = X_ji[i].detach().numpy().reshape(-1, 1)  # Reshape to (200, 1)\n",
    "            kde.fit(sample)\n",
    "            kde_estimates = torch.exp(torch.tensor(kde.score_samples(sample), dtype=torch.float32))\n",
    "            kde_X_ji[i] = kde_estimates.squeeze()\n",
    "        min_value = torch.min(kde_X_ji)\n",
    "        max_value = torch.max(kde_X_ji)\n",
    "\n",
    "        # Normalize the KDE values to the range [0, 1]\n",
    "        normalized_kde_values = (kde_X_ji - min_value) / (max_value - min_value)\n",
    "        weights = 1 - (0.9 * normalized_kde_values)\n",
    "        weights = torch.clamp(weights, epsilon)\n",
    "        weights_sum = torch.sum(weights)\n",
    "        normalized_weights = weights / weights_sum\n",
    "        epsilon = 1e-8\n",
    "        Z_ji = torch.clamp(Z_ji, epsilon)\n",
    "        loss = X_ji * torch.log(Z_ji) + C_j * torch.exp(-Z_ji)\n",
    "        #print(\"loss\")\n",
    "        #print(loss)\n",
    "        #print(\"weights\")\n",
    "        #print(normalized_weights)\n",
    "        # compute mean over batch to normalize due to varying batch sizes\n",
    "        return (normalized_weights*loss).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "422082b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(targets, outputs):\n",
    "    indices = range(len(targets[0]))\n",
    "\n",
    "    fig, axs = plt.subplots(3, 3, figsize=(15,15))\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            axs[i, j].scatter(indices, targets[i+j*3], s=5)\n",
    "            axs[i, j].scatter(indices, outputs.detach().numpy()[i+j*3], s=5)\n",
    "            axs[i, j].set_ylim(-0.25, 1.3)\n",
    "\n",
    "    plt.xlabel('Index')\n",
    "    plt.ylabel('Elongation Rates')\n",
    "    plt.legend(['GLM Elongation Rate', 'NN Elongation Rate'], loc='upper center', bbox_to_anchor=(0.5, -0.6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8360fc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6c28ed03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m     18\u001b[0m model\u001b[39m.\u001b[39mtrain()\n\u001b[0;32m---> 19\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m trndl:\n\u001b[1;32m     20\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     21\u001b[0m     \u001b[39m#Y_ji_batch = batch['Y_ji']\u001b[39;00m\n",
      "File \u001b[0;32m~/software/anaconda3/envs/cnn-motif/lib/python3.8/site-packages/torch/utils/data/dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    632\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    634\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    635\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    636\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/software/anaconda3/envs/cnn-motif/lib/python3.8/site-packages/torch/utils/data/dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    676\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 677\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    678\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    679\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/software/anaconda3/envs/cnn-motif/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/software/anaconda3/envs/cnn-motif/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/software/anaconda3/envs/cnn-motif/lib/python3.8/site-packages/torch/utils/data/dataset.py:298\u001b[0m, in \u001b[0;36mSubset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(idx, \u001b[39mlist\u001b[39m):\n\u001b[1;32m    297\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindices[i] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m idx]]\n\u001b[0;32m--> 298\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindices[idx]]\n",
      "Cell \u001b[0;32mIn[11], line 16\u001b[0m, in \u001b[0;36mCustomDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, idx):\n\u001b[1;32m     14\u001b[0m     \u001b[39mreturn\u001b[39;00m {\n\u001b[1;32m     15\u001b[0m         \u001b[39m#'Y_ji':  torch.tensor(self.Y_ji[idx], dtype=torch.float32),\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mX_ji\u001b[39m\u001b[39m'\u001b[39m: torch\u001b[39m.\u001b[39;49mtensor(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mX_ji[idx], dtype\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mfloat32),\n\u001b[1;32m     17\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mC_j\u001b[39m\u001b[39m'\u001b[39m: torch\u001b[39m.\u001b[39mtensor(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mC_j[idx], dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat32),\n\u001b[1;32m     18\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mZ_ji\u001b[39m\u001b[39m'\u001b[39m: torch\u001b[39m.\u001b[39mtensor(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mZ_ji[idx], dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat32)\n\u001b[1;32m     19\u001b[0m     }\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n",
    "\n",
    "\n",
    "num_epochs = 50\n",
    "\n",
    "loss_hist_train = [0] * num_epochs\n",
    "loss_hist_valid = [0] * num_epochs\n",
    "\n",
    "loss_fn = CustomLoss_1()#nn.L1Loss()#nn.MSELoss()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'Epoch {epoch+1}')\n",
    "    model.train()\n",
    "    for batch in trndl:\n",
    "        optimizer.zero_grad()\n",
    "        #Y_ji_batch = batch['Y_ji']\n",
    "        X_ji_batch = batch['X_ji']\n",
    "        C_j_batch = batch['C_j']\n",
    "        outputs = model(X_ji_batch)\n",
    "        loss = loss_fn(X_ji_batch, C_j_batch, outputs)\n",
    "        #loss = loss_fn(batch['Z_ji'], outputs)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_hist_train[epoch] += loss.item()\n",
    "        #if epoch == 49:\n",
    "         #   plot_data(batch['Z_ji'], outputs)\n",
    "    loss_hist_train[epoch] /= len(trndl.dataset)\n",
    "    scheduler.step()\n",
    "    \n",
    "    #model.eval()\n",
    "    #with torch.no_grad():\n",
    "    #    for batch in valdl:\n",
    "    #        Y_ji_batch = batch['Y_ji']\n",
    "    #        X_ji_batch = batch['X_ji']\n",
    "    #        C_j_batch = batch['C_j']\n",
    "    #        outputs = model(Y_ji_batch)\n",
    "    #        loss = loss_fn(X_ji_batch, C_j_batch, outputs)\n",
    "            #loss = loss_fn(batch['Z_ji'], outputs)\n",
    "    #        loss_hist_valid[epoch] += loss.item()\n",
    "    #    loss_hist_valid[epoch] /= len(valdl.dataset)\n",
    "    \n",
    "    print(f'Epoch {epoch+1} trn_loss: '\n",
    "          f'{loss_hist_train[epoch]:.4f}')# val_loss: '\n",
    "          #f'{loss_hist_valid[epoch]:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94841213",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "epochs = range(1, len(loss_hist_train) + 1)\n",
    "plt.plot(epochs, loss_hist_train, label='train_loss')\n",
    "plt.plot(epochs, loss_hist_valid, label='valid_loss')\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7239c5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "inputs = next(iter(trndl))#tstdl)) \n",
    "print(\"number of samples: \" + str(len(inputs)))\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(inputs['Y_ji'])\n",
    "    \n",
    "#outputs = torch.exp(outputs)\n",
    "print(outputs)\n",
    "\n",
    "targets = inputs['Z_ji']\n",
    "\n",
    "plot_data(targets, outputs)\n",
    "\n",
    "#for batch in trndl:\n",
    "#    targets = inputs['Z_ji']\n",
    "#    outputs = model(inputs['X_ji'])#'Y_ji'])\n",
    "#    outputs = torch.exp(outputs)\n",
    "    \n",
    "#    plot_data(targets, outputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
