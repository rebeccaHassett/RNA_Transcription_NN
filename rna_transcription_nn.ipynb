{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "35ba1335",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.utils.data as td\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "froot = './data/k562_main'\n",
    "\n",
    "df = pd.read_csv(froot + \".csv\")#, chunksize=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "25c67eaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   seqnames    start      end strand  ensembl_gene_id  score      ctcf  \\\n",
      "0         1  3859709  3859709      +  ENSG00000169598    0.0 -0.010876   \n",
      "1         1  3859710  3859710      +  ENSG00000169598    0.0 -0.010887   \n",
      "2         1  3859711  3859711      +  ENSG00000169598    0.0 -0.010902   \n",
      "3         1  3859712  3859712      +  ENSG00000169598    0.0 -0.010920   \n",
      "4         1  3859713  3859713      +  ENSG00000169598    0.0 -0.010941   \n",
      "\n",
      "   h3k36me3   h3k4me1  h3k79me2  ...       sj5       sj3       dms      rpts  \\\n",
      "0  0.353765 -0.078256 -0.156547  ... -0.028916 -0.057178 -0.307549  0.249626   \n",
      "1  0.347003 -0.077117 -0.155891  ... -0.028916 -0.057178 -0.307549  0.249626   \n",
      "2  0.340295 -0.075994 -0.155236  ... -0.028916 -0.057178 -0.307549  0.249626   \n",
      "3  0.333641 -0.074887 -0.154583  ... -0.028916 -0.057178 -0.307549  0.249626   \n",
      "4  0.327043 -0.073795 -0.153930  ... -0.028916 -0.057178 -0.307549  0.249626   \n",
      "\n",
      "   wgbs      A         T         G         C  lambda_alphaj  \n",
      "0   0.0 -0.625 -0.678443  1.954571 -0.494439       0.014335  \n",
      "1   0.0 -0.625 -0.678443  1.954571 -0.494439       0.014335  \n",
      "2   0.0 -0.625  1.473964 -0.511621 -0.494439       0.014335  \n",
      "3   0.0 -0.625  1.473964 -0.511621 -0.494439       0.014335  \n",
      "4   0.0 -0.625 -0.678443  1.954571 -0.494439       0.014335  \n",
      "\n",
      "[5 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7b54d1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['gene_length'] = df.groupby('ensembl_gene_id')['ensembl_gene_id'].transform('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "80394636",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = df[df['gene_length'] == 2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10b24ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0           20000\n",
      "1           20000\n",
      "2           20000\n",
      "3           20000\n",
      "4           20000\n",
      "            ...  \n",
      "61709392      NaN\n",
      "61709393      NaN\n",
      "61709394      NaN\n",
      "61709395      NaN\n",
      "61709396      NaN\n",
      "Name: bucket, Length: 61709397, dtype: category\n",
      "Categories (18, int64): [2000 < 4000 < 6000 < 8000 ... 30000 < 32000 < 34000 < 36000]\n"
     ]
    }
   ],
   "source": [
    "bucket_boundaries = list(range(0, 38000, 2000))\n",
    "labels = bucket_boundaries[1:]\n",
    "\n",
    "\n",
    "df['bucket'] = pd.cut(df['gene_length'], bins=bucket_boundaries, labels=labels, right=False)\n",
    "print(df['bucket'])\n",
    "\n",
    "df.dropna(subset=['bucket'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c23abb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32000    1180951\n",
      "20000    1056439\n",
      "18000    1026786\n",
      "30000     963932\n",
      "36000     963478\n",
      "22000     932440\n",
      "28000     895678\n",
      "24000     870659\n",
      "26000     859178\n",
      "14000     826929\n",
      "12000     820942\n",
      "16000     779045\n",
      "34000     711680\n",
      "10000     684799\n",
      "8000      530528\n",
      "6000      435971\n",
      "4000      205804\n",
      "2000       12348\n",
      "Name: bucket, dtype: int64\n",
      "13757587\n"
     ]
    }
   ],
   "source": [
    "# How many values are in each bucket?\n",
    "bucket_counts = df['bucket'].value_counts()\n",
    "\n",
    "print(bucket_counts)\n",
    "\n",
    "# total values\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "24636895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ctcf', 'h3k36me3', 'h3k4me1', 'h3k79me2', 'h3k9me1', 'h3k9me3', 'h4k20me1', 'sj5', 'sj3', 'dms', 'rpts', 'wgbs', 'A']\n",
      "['T', 'G', 'C', 'lambda_alphaj']\n"
     ]
    }
   ],
   "source": [
    "column_names = filtered_df.columns.tolist()\n",
    "feature_names = column_names[6:-5]\n",
    "nucleotides = column_names[-5:-1]\n",
    "print(feature_names)\n",
    "print(nucleotides)\n",
    "\n",
    "# process read counts\n",
    "X_ji = filtered_df.groupby('ensembl_gene_id')['score'].apply(list).tolist() \n",
    "\n",
    "num_samples = len(X_ji)\n",
    "\n",
    "features = []\n",
    "#for feature_name in feature_names:\n",
    "    #features.append(df.groupby(ensembl_gene_id)[feature_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d504b303",
   "metadata": {},
   "outputs": [],
   "source": [
    "C_j = filtered_df.groupby('ensembl_gene_id')['lambda_alphaj'].apply(list).tolist() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "35f18812",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, X_ji, C_j):\n",
    "        self.X_ji = X_ji\n",
    "        self.C_j = C_j\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X_ji)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'X_ji': torch.tensor(self.X_ji[idx], dtype=torch.float32),\n",
    "            'C_j': torch.tensor(self.C_j[idx], dtype=torch.float32)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5977e736",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CustomDataset(X_ji, C_j)\n",
    "\n",
    "trnset, valset, tstset = td.random_split(dataset, [0.5,0.25,0.25])\n",
    "\n",
    "trndl = DataLoader(trnset, batch_size=64, shuffle=True)\n",
    "tstdl = DataLoader(tstset, batch_size=64, shuffle=True)\n",
    "valdl = DataLoader(valset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2404f7d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (lstm): LSTM(2000, 32, batch_first=True)\n",
      "  (fc): Linear(in_features=32, out_features=2000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Model, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, inputs):#, lengths):\n",
    "        #packed_inputs = nn.utils.rnn.pack_padded_sequence(inputs, lengths, batch_first=True, enforce_sorted=False)\n",
    "        outputs, _ = self.lstm(inputs)\n",
    "        #outputs, _ = nn.utils.rnn.pad_packed_sequence(packed_outputs, batch_first=True)\n",
    "        predictions = self.fc(outputs)\n",
    "        return predictions\n",
    "        \n",
    "input_size = 2000#num_samples\n",
    "hidden_size = 32\n",
    "output_size = 2000#num_samples\n",
    "\n",
    "model = Model(input_size, hidden_size, output_size)\n",
    "# check model\n",
    "print(model)\n",
    "\n",
    "#x = torch.ones((64,2000))\n",
    "#print(model(x).shape)\n",
    "#nparm = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "#print(\"Number of parameters: \" + str(nparm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f03d0d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomLoss, self).__init__()\n",
    "\n",
    "    def forward(self, X_ji, C_j, Z_ji):\n",
    "        loss = X_ji * Z_ji + C_j * torch.exp(-Z_ji)\n",
    "        # compute mean over batch to normalize due to varying batch sizes\n",
    "        return loss.mean() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6c28ed03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 0.007333577144891024\n",
      "Epoch [2/100], Loss: 0.007033327128738165\n",
      "Epoch [3/100], Loss: 0.0061981105245649815\n",
      "Epoch [4/100], Loss: 0.005685880314558744\n",
      "Epoch [5/100], Loss: 0.004781608935445547\n",
      "Epoch [6/100], Loss: 0.004242316819727421\n",
      "Epoch [7/100], Loss: 0.003812007373198867\n",
      "Epoch [8/100], Loss: 0.0036222832277417183\n",
      "Epoch [9/100], Loss: 0.0026076403446495533\n",
      "Epoch [10/100], Loss: 0.0025629589799791574\n",
      "Epoch [11/100], Loss: 0.0020957428496330976\n",
      "Epoch [12/100], Loss: 0.00139122165273875\n",
      "Epoch [13/100], Loss: 0.0005929270992055535\n",
      "Epoch [14/100], Loss: 0.0005200934829190373\n",
      "Epoch [15/100], Loss: -0.00042709585977718234\n",
      "Epoch [16/100], Loss: -0.000947242951951921\n",
      "Epoch [17/100], Loss: -0.0011818311177194118\n",
      "Epoch [18/100], Loss: -0.0019143166719004512\n",
      "Epoch [19/100], Loss: -0.0026030102744698524\n",
      "Epoch [20/100], Loss: -0.0026214446406811476\n",
      "Epoch [21/100], Loss: -0.0032371636480093002\n",
      "Epoch [22/100], Loss: -0.0036363110411912203\n",
      "Epoch [23/100], Loss: -0.004319961182773113\n",
      "Epoch [24/100], Loss: -0.004703646060079336\n",
      "Epoch [25/100], Loss: -0.005184858571738005\n",
      "Epoch [26/100], Loss: -0.005906635895371437\n",
      "Epoch [27/100], Loss: -0.006449349224567413\n",
      "Epoch [28/100], Loss: -0.006850846111774445\n",
      "Epoch [29/100], Loss: -0.007472938857972622\n",
      "Epoch [30/100], Loss: -0.007678466849029064\n",
      "Epoch [31/100], Loss: -0.008394391275942326\n",
      "Epoch [32/100], Loss: -0.00892081018537283\n",
      "Epoch [33/100], Loss: -0.009328422136604786\n",
      "Epoch [34/100], Loss: -0.009983020834624767\n",
      "Epoch [35/100], Loss: -0.00958974938839674\n",
      "Epoch [36/100], Loss: -0.010894154198467731\n",
      "Epoch [37/100], Loss: -0.011007013730704784\n",
      "Epoch [38/100], Loss: -0.011749302968382835\n",
      "Epoch [39/100], Loss: -0.011907831765711308\n",
      "Epoch [40/100], Loss: -0.012495501898229122\n",
      "Epoch [41/100], Loss: -0.01321902871131897\n",
      "Epoch [42/100], Loss: -0.013557552359998226\n",
      "Epoch [43/100], Loss: -0.014043902978301048\n",
      "Epoch [44/100], Loss: -0.01425522193312645\n",
      "Epoch [45/100], Loss: -0.014925051480531693\n",
      "Epoch [46/100], Loss: -0.014885012991726398\n",
      "Epoch [47/100], Loss: -0.015845483168959618\n",
      "Epoch [48/100], Loss: -0.01620994508266449\n",
      "Epoch [49/100], Loss: -0.016179213300347328\n",
      "Epoch [50/100], Loss: -0.016875416040420532\n",
      "Epoch [51/100], Loss: -0.01750267669558525\n",
      "Epoch [52/100], Loss: -0.0181552916765213\n",
      "Epoch [53/100], Loss: -0.018603330478072166\n",
      "Epoch [54/100], Loss: -0.019118687137961388\n",
      "Epoch [55/100], Loss: -0.01893036998808384\n",
      "Epoch [56/100], Loss: -0.019315825775265694\n",
      "Epoch [57/100], Loss: -0.019858304411172867\n",
      "Epoch [58/100], Loss: -0.02072776108980179\n",
      "Epoch [59/100], Loss: -0.020766692236065865\n",
      "Epoch [60/100], Loss: -0.021243955940008163\n",
      "Epoch [61/100], Loss: -0.021545471623539925\n",
      "Epoch [62/100], Loss: -0.02213623747229576\n",
      "Epoch [63/100], Loss: -0.022639857605099678\n",
      "Epoch [64/100], Loss: -0.02286640554666519\n",
      "Epoch [65/100], Loss: -0.02378552220761776\n",
      "Epoch [66/100], Loss: -0.023633359000086784\n",
      "Epoch [67/100], Loss: -0.024156194180250168\n",
      "Epoch [68/100], Loss: -0.024146640673279762\n",
      "Epoch [69/100], Loss: -0.02499321475625038\n",
      "Epoch [70/100], Loss: -0.02513718046247959\n",
      "Epoch [71/100], Loss: -0.025412114337086678\n",
      "Epoch [72/100], Loss: -0.025979794561862946\n",
      "Epoch [73/100], Loss: -0.025857578963041306\n",
      "Epoch [74/100], Loss: -0.026652829721570015\n",
      "Epoch [75/100], Loss: -0.02698853425681591\n",
      "Epoch [76/100], Loss: -0.027607673779129982\n",
      "Epoch [77/100], Loss: -0.027878427878022194\n",
      "Epoch [78/100], Loss: -0.02842600643634796\n",
      "Epoch [79/100], Loss: -0.02858101576566696\n",
      "Epoch [80/100], Loss: -0.029001891613006592\n",
      "Epoch [81/100], Loss: -0.02930833026766777\n",
      "Epoch [82/100], Loss: -0.02935005910694599\n",
      "Epoch [83/100], Loss: -0.030330946668982506\n",
      "Epoch [84/100], Loss: -0.030637061223387718\n",
      "Epoch [85/100], Loss: -0.030836662277579308\n",
      "Epoch [86/100], Loss: -0.030905717983841896\n",
      "Epoch [87/100], Loss: -0.03156592324376106\n",
      "Epoch [88/100], Loss: -0.0320756696164608\n",
      "Epoch [89/100], Loss: -0.03275546804070473\n",
      "Epoch [90/100], Loss: -0.0327860452234745\n",
      "Epoch [91/100], Loss: -0.03330423682928085\n",
      "Epoch [92/100], Loss: -0.033298805356025696\n",
      "Epoch [93/100], Loss: -0.03356843441724777\n",
      "Epoch [94/100], Loss: -0.03418903797864914\n",
      "Epoch [95/100], Loss: -0.03460780158638954\n",
      "Epoch [96/100], Loss: -0.034633006900548935\n",
      "Epoch [97/100], Loss: -0.03475914150476456\n",
      "Epoch [98/100], Loss: -0.035453032702207565\n",
      "Epoch [99/100], Loss: -0.035414960235357285\n",
      "Epoch [100/100], Loss: -0.03597927838563919\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 100\n",
    "\n",
    "loss_fn = CustomLoss()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in trndl:\n",
    "        optimizer.zero_grad()\n",
    "        #inputs = batch\n",
    "        X_ji_batch = batch['X_ji']\n",
    "        C_j_batch = batch['C_j']\n",
    "        #lengths = [len(sample) for sample in inputs]\n",
    "        #padded_inputs = pad_sequence([torch.tensor(sample) for sample in inputs], batch_first=True)\n",
    "        outputs = model(X_ji_batch)#, lengths)\n",
    "        loss = loss_fn(X_ji_batch, C_j_batch, outputs)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "94841213",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hist' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m \u001b[39mimport\u001b[39;00m pyplot \u001b[39mas\u001b[39;00m plt\n\u001b[0;32m----> 2\u001b[0m epochs \u001b[39m=\u001b[39m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39mlen\u001b[39m(hist[\u001b[39m0\u001b[39m]) \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[1;32m      3\u001b[0m plt\u001b[39m.\u001b[39mplot(epochs, hist[\u001b[39m0\u001b[39m], label\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtrain_loss\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m plt\u001b[39m.\u001b[39mplot(epochs, hist[\u001b[39m1\u001b[39m], label\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mvalid_loss\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'hist' is not defined"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "epochs = range(1, len(hist[0]) + 1)\n",
    "plt.plot(epochs, hist[0], label='train_loss')\n",
    "plt.plot(epochs, hist[1], label='valid_loss')\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "9756b162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Mean Absolute Error (MAE): 0.019\n",
      "Overall Mean Squared Error (MSE): 0.002\n"
     ]
    }
   ],
   "source": [
    "mae = []\n",
    "mse = []\n",
    "for inputs, labels in tstdl:\n",
    "    #interpret_model(inputs, labels)\n",
    "    outputs = model(inputs)\n",
    "    mae.append(torch.mean(torch.abs(outputs - labels), dim=0))\n",
    "    mse.append(torch.mean((outputs - labels)**2, dim=0))\n",
    "\n",
    "mean_mae = torch.mean(torch.stack(mae))    \n",
    "mean_mse = torch.mean(torch.stack(mse))\n",
    "print(\"Overall Mean Absolute Error (MAE):\", round(mean_mae.item(), 3))\n",
    "print(\"Overall Mean Squared Error (MSE):\", round(mean_mse.item(), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7239c5d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of samples: 2\n",
      "tensor(0.3920)\n",
      "tensor(0.3050)\n",
      "tensor(0.2662)\n",
      "tensor(0.2966)\n",
      "tensor(0.2516)\n",
      "tensor(0.2622)\n",
      "tensor(0.3023)\n",
      "tensor(0.2802)\n",
      "tensor(0.2806)\n",
      "tensor(0.2848)\n",
      "tensor(0.2579)\n",
      "tensor(0.3045)\n",
      "tensor(0.2646)\n",
      "tensor(0.3164)\n",
      "tensor(0.2872)\n",
      "tensor(0.3833)\n",
      "tensor(0.2627)\n",
      "tensor(0.2855)\n",
      "tensor(0.2743)\n",
      "tensor(0.2628)\n",
      "tensor(0.2645)\n",
      "tensor(0.2718)\n",
      "tensor(0.2915)\n",
      "tensor(0.4143)\n",
      "tensor(0.3008)\n",
      "tensor(0.3436)\n",
      "tensor(0.2551)\n",
      "tensor(0.3803)\n",
      "tensor(0.2501)\n",
      "tensor(0.3127)\n",
      "tensor(0.3424)\n",
      "tensor(0.2765)\n",
      "tensor(0.2524)\n",
      "tensor(0.2663)\n",
      "tensor(0.2939)\n",
      "tensor(0.2765)\n",
      "tensor(0.2642)\n",
      "tensor(0.3266)\n",
      "tensor(0.2568)\n",
      "tensor(0.3434)\n",
      "tensor(0.2668)\n",
      "tensor(0.2947)\n",
      "tensor(0.2507)\n",
      "tensor(0.2727)\n",
      "tensor(0.3401)\n",
      "tensor(0.2661)\n",
      "tensor(0.2554)\n",
      "tensor(0.2852)\n",
      "tensor(0.2720)\n",
      "tensor(0.3244)\n",
      "tensor(0.2519)\n",
      "tensor(0.2722)\n",
      "tensor(0.2776)\n",
      "tensor(0.2670)\n",
      "tensor(0.2678)\n",
      "tensor(0.3680)\n",
      "tensor(0.2944)\n",
      "tensor(0.2704)\n",
      "tensor(0.3550)\n",
      "tensor(0.2833)\n",
      "tensor(0.2954)\n",
      "tensor(0.2583)\n",
      "tensor(0.3508)\n",
      "tensor(0.3322)\n",
      "tensor(0.3420)\n",
      "tensor(0.2509)\n",
      "tensor(0.2998)\n",
      "tensor(0.2749)\n",
      "tensor(0.2528)\n",
      "tensor(0.2593)\n",
      "tensor(0.3095)\n",
      "tensor(0.2531)\n",
      "tensor(0.2652)\n",
      "tensor(0.3960)\n",
      "tensor(0.2941)\n",
      "tensor(0.2993)\n",
      "tensor(0.2573)\n",
      "tensor(0.2511)\n",
      "tensor(0.2793)\n",
      "tensor(0.2549)\n",
      "tensor(0.3058)\n",
      "tensor(0.3360)\n",
      "tensor(0.3239)\n",
      "tensor(0.2721)\n",
      "tensor(0.2751)\n",
      "tensor(0.2645)\n",
      "tensor(0.2620)\n",
      "tensor(0.2632)\n",
      "tensor(0.2853)\n",
      "tensor(0.3370)\n",
      "tensor(0.3104)\n",
      "tensor(0.2595)\n",
      "tensor(0.2828)\n",
      "tensor(0.2838)\n",
      "tensor(0.3035)\n",
      "tensor(0.2646)\n",
      "tensor(0.2622)\n",
      "tensor(0.2756)\n",
      "tensor(0.4304)\n",
      "tensor(0.3596)\n",
      "tensor(0.2542)\n",
      "tensor(0.2503)\n",
      "tensor(0.3545)\n",
      "tensor(0.2596)\n",
      "tensor(0.2836)\n",
      "tensor(0.2708)\n",
      "tensor(0.2744)\n",
      "tensor(0.2650)\n",
      "tensor(0.2659)\n",
      "tensor(0.3428)\n",
      "tensor(0.2624)\n",
      "tensor(0.2871)\n",
      "tensor(0.2616)\n",
      "tensor(0.2785)\n",
      "tensor(0.2947)\n",
      "tensor(0.2704)\n",
      "tensor(0.4078)\n",
      "tensor(0.3269)\n",
      "tensor(0.2752)\n",
      "tensor(0.2672)\n",
      "tensor(0.2754)\n",
      "tensor(0.2709)\n",
      "tensor(0.2945)\n",
      "tensor(0.4073)\n",
      "tensor(0.2570)\n",
      "tensor(0.3164)\n",
      "tensor(0.3207)\n",
      "tensor(0.2875)\n",
      "tensor(0.3107)\n",
      "tensor(0.2747)\n",
      "tensor(0.3090)\n",
      "tensor(0.3265)\n",
      "tensor(0.2504)\n",
      "tensor(0.3771)\n",
      "tensor(0.2740)\n",
      "tensor(0.2702)\n",
      "tensor(0.2551)\n",
      "tensor(0.2653)\n",
      "tensor(0.2538)\n",
      "tensor(0.2842)\n",
      "tensor(0.3205)\n",
      "tensor(0.3013)\n",
      "tensor(0.3397)\n",
      "tensor(0.3673)\n",
      "tensor(0.2704)\n",
      "tensor(0.3307)\n",
      "tensor(0.3030)\n",
      "tensor(0.2791)\n",
      "tensor(0.3208)\n",
      "tensor(0.2583)\n",
      "tensor(0.2872)\n",
      "tensor(0.2622)\n",
      "tensor(0.2860)\n",
      "tensor(0.2963)\n",
      "tensor(0.2689)\n",
      "tensor(0.2814)\n",
      "tensor(0.2882)\n",
      "tensor(0.2838)\n",
      "tensor(0.3830)\n",
      "tensor(0.2516)\n",
      "tensor(0.3151)\n",
      "tensor(0.2517)\n",
      "tensor(0.3222)\n",
      "tensor(0.2981)\n",
      "tensor(0.3181)\n",
      "tensor(0.3402)\n",
      "tensor(0.3695)\n",
      "tensor(0.3450)\n",
      "tensor(0.2519)\n",
      "tensor(0.2731)\n",
      "tensor(0.3672)\n",
      "tensor(0.3008)\n",
      "tensor(0.2613)\n",
      "tensor(0.3333)\n",
      "tensor(0.2568)\n",
      "tensor(0.2925)\n",
      "tensor(0.2778)\n",
      "tensor(0.4268)\n",
      "tensor(0.3967)\n",
      "tensor(0.3175)\n",
      "tensor(0.3672)\n",
      "tensor(0.3023)\n",
      "tensor(0.2584)\n",
      "tensor(0.4125)\n",
      "tensor(0.3054)\n",
      "tensor(0.2601)\n",
      "tensor(0.2712)\n",
      "tensor(0.2816)\n",
      "tensor(0.2811)\n",
      "tensor(0.3049)\n",
      "tensor(0.3173)\n",
      "tensor(0.2763)\n",
      "tensor(0.2511)\n",
      "tensor(0.2531)\n",
      "tensor(0.2828)\n",
      "tensor(0.3177)\n",
      "tensor(0.3933)\n",
      "tensor(0.2932)\n",
      "tensor(0.2664)\n",
      "tensor(0.2943)\n",
      "tensor(0.2746)\n",
      "tensor(0.2826)\n",
      "tensor(0.2689)\n",
      "tensor(0.3060)\n",
      "tensor(0.3177)\n",
      "tensor(0.2574)\n",
      "tensor(0.2554)\n",
      "tensor(0.2633)\n",
      "tensor(0.3322)\n",
      "tensor(0.2989)\n",
      "tensor(0.2627)\n",
      "tensor(0.3112)\n",
      "tensor(0.3086)\n",
      "tensor(0.3359)\n",
      "tensor(0.2631)\n",
      "tensor(0.3023)\n",
      "tensor(0.2550)\n",
      "tensor(0.2567)\n",
      "tensor(0.2992)\n",
      "tensor(0.2694)\n",
      "tensor(0.3111)\n",
      "tensor(0.2952)\n",
      "tensor(0.3135)\n",
      "tensor(0.2512)\n",
      "tensor(0.2515)\n",
      "tensor(0.2527)\n",
      "tensor(0.2980)\n",
      "tensor(0.3505)\n",
      "tensor(0.2766)\n",
      "tensor(0.2523)\n",
      "tensor(0.2884)\n",
      "tensor(0.3955)\n",
      "tensor(0.3007)\n",
      "tensor(0.2617)\n",
      "tensor(0.3508)\n",
      "tensor(0.3481)\n",
      "tensor(0.2646)\n",
      "tensor(0.2603)\n",
      "tensor(0.2611)\n",
      "tensor(0.2806)\n",
      "tensor(0.2866)\n",
      "tensor(0.2611)\n",
      "tensor(0.2704)\n",
      "tensor(0.3129)\n",
      "tensor(0.2891)\n",
      "tensor(0.3448)\n",
      "tensor(0.2792)\n",
      "tensor(0.2505)\n",
      "tensor(0.2558)\n",
      "tensor(0.2975)\n",
      "tensor(0.2759)\n",
      "tensor(0.3637)\n",
      "tensor(0.2639)\n",
      "tensor(0.2844)\n",
      "tensor(0.2970)\n",
      "tensor(0.3947)\n",
      "tensor(0.3124)\n",
      "tensor(0.2665)\n",
      "tensor(0.2755)\n",
      "tensor(0.2500)\n",
      "tensor(0.3229)\n",
      "tensor(0.2920)\n",
      "tensor(0.3149)\n",
      "tensor(0.2707)\n",
      "tensor(0.3021)\n",
      "tensor(0.2557)\n",
      "tensor(0.2692)\n",
      "tensor(0.4604)\n",
      "tensor(0.3316)\n",
      "tensor(0.2759)\n",
      "tensor(0.3101)\n",
      "tensor(0.2631)\n",
      "tensor(0.2917)\n",
      "tensor(0.2564)\n",
      "tensor(0.3225)\n",
      "tensor(0.3410)\n",
      "tensor(0.3065)\n",
      "tensor(0.2643)\n",
      "tensor(0.3395)\n",
      "tensor(0.2560)\n",
      "tensor(0.2542)\n",
      "tensor(0.3576)\n",
      "tensor(0.3726)\n",
      "tensor(0.2599)\n",
      "tensor(0.2748)\n",
      "tensor(0.2665)\n",
      "tensor(0.2513)\n",
      "tensor(0.3154)\n",
      "tensor(0.2725)\n",
      "tensor(0.3135)\n",
      "tensor(0.2848)\n",
      "tensor(0.2532)\n",
      "tensor(0.2792)\n",
      "tensor(0.2734)\n",
      "tensor(0.2862)\n",
      "tensor(0.2866)\n",
      "tensor(0.2519)\n",
      "tensor(0.2513)\n",
      "tensor(0.2591)\n",
      "tensor(0.2510)\n",
      "tensor(0.2611)\n",
      "tensor(0.2738)\n",
      "tensor(0.2744)\n",
      "tensor(0.2944)\n",
      "tensor(0.2681)\n",
      "tensor(0.2509)\n",
      "tensor(0.2568)\n",
      "tensor(0.2649)\n",
      "tensor(0.2864)\n",
      "tensor(0.2746)\n",
      "tensor(0.3157)\n",
      "tensor(0.2625)\n",
      "tensor(0.3094)\n",
      "tensor(0.2860)\n",
      "tensor(0.2564)\n",
      "tensor(0.2549)\n",
      "tensor(0.2596)\n",
      "tensor(0.3919)\n",
      "tensor(0.2828)\n",
      "tensor(0.2778)\n",
      "tensor(0.2550)\n",
      "tensor(0.2671)\n",
      "tensor(0.2517)\n",
      "tensor(0.2991)\n",
      "tensor(0.2839)\n",
      "tensor(0.2833)\n",
      "tensor(0.2821)\n",
      "tensor(0.2515)\n",
      "tensor(0.3653)\n",
      "tensor(0.2983)\n",
      "tensor(0.3869)\n",
      "tensor(0.2873)\n",
      "tensor(0.3000)\n",
      "tensor(0.2595)\n",
      "tensor(0.2534)\n",
      "tensor(0.2801)\n",
      "tensor(0.2965)\n",
      "tensor(0.2998)\n",
      "tensor(0.2758)\n",
      "tensor(0.3315)\n",
      "tensor(0.2610)\n",
      "tensor(0.3567)\n",
      "tensor(0.2817)\n",
      "tensor(0.3654)\n",
      "tensor(0.2607)\n",
      "tensor(0.2621)\n",
      "tensor(0.2841)\n",
      "tensor(0.2886)\n",
      "tensor(0.2785)\n",
      "tensor(0.3100)\n",
      "tensor(0.3099)\n",
      "tensor(0.3238)\n",
      "tensor(0.3264)\n",
      "tensor(0.3385)\n",
      "tensor(0.3233)\n",
      "tensor(0.2540)\n",
      "tensor(0.2587)\n",
      "tensor(0.2606)\n",
      "tensor(0.3018)\n",
      "tensor(0.2568)\n",
      "tensor(0.2562)\n",
      "tensor(0.3157)\n",
      "tensor(0.2695)\n",
      "tensor(0.2558)\n",
      "tensor(0.2764)\n",
      "tensor(0.3327)\n",
      "tensor(0.2660)\n",
      "tensor(0.3033)\n",
      "tensor(0.3058)\n",
      "tensor(0.2649)\n",
      "tensor(0.2526)\n",
      "tensor(0.2616)\n",
      "tensor(0.2669)\n",
      "tensor(0.2595)\n",
      "tensor(0.3074)\n",
      "tensor(0.2823)\n",
      "tensor(0.3647)\n",
      "tensor(0.2668)\n",
      "tensor(0.3539)\n",
      "tensor(0.2925)\n",
      "tensor(0.2721)\n",
      "tensor(0.2675)\n",
      "tensor(0.2787)\n",
      "tensor(0.2784)\n",
      "tensor(0.2763)\n",
      "tensor(0.3038)\n",
      "tensor(0.2732)\n",
      "tensor(0.2709)\n",
      "tensor(0.2820)\n",
      "tensor(0.3427)\n",
      "tensor(0.2544)\n",
      "tensor(0.2713)\n",
      "tensor(0.2581)\n",
      "tensor(0.2704)\n",
      "tensor(0.2768)\n",
      "tensor(0.2616)\n",
      "tensor(0.3012)\n",
      "tensor(0.2754)\n",
      "tensor(0.2552)\n",
      "tensor(0.2831)\n",
      "tensor(0.2877)\n",
      "tensor(0.2795)\n",
      "tensor(0.3109)\n",
      "tensor(0.2510)\n",
      "tensor(0.2521)\n",
      "tensor(0.2501)\n",
      "tensor(0.2774)\n",
      "tensor(0.2895)\n",
      "tensor(0.3528)\n",
      "tensor(0.2553)\n",
      "tensor(0.2546)\n",
      "tensor(0.2723)\n",
      "tensor(0.2548)\n",
      "tensor(0.2668)\n",
      "tensor(0.4080)\n",
      "tensor(0.2653)\n",
      "tensor(0.2956)\n",
      "tensor(0.3392)\n",
      "tensor(0.2678)\n",
      "tensor(0.3608)\n",
      "tensor(0.2910)\n",
      "tensor(0.3500)\n",
      "tensor(0.3225)\n",
      "tensor(0.2677)\n",
      "tensor(0.2717)\n",
      "tensor(0.3361)\n",
      "tensor(0.3416)\n",
      "tensor(0.3489)\n",
      "tensor(0.2823)\n",
      "tensor(0.3023)\n",
      "tensor(0.3436)\n",
      "tensor(0.3028)\n",
      "tensor(0.3266)\n",
      "tensor(0.3002)\n",
      "tensor(0.2805)\n",
      "tensor(0.2526)\n",
      "tensor(0.2876)\n",
      "tensor(0.3392)\n",
      "tensor(0.2688)\n",
      "tensor(0.2698)\n",
      "tensor(0.3263)\n",
      "tensor(0.3345)\n",
      "tensor(0.3253)\n",
      "tensor(0.4837)\n",
      "tensor(0.3152)\n",
      "tensor(0.3255)\n",
      "tensor(0.2779)\n",
      "tensor(0.3476)\n",
      "tensor(0.2550)\n",
      "tensor(0.2580)\n",
      "tensor(0.2669)\n",
      "tensor(0.2658)\n",
      "tensor(0.3600)\n",
      "tensor(0.3264)\n",
      "tensor(0.2973)\n",
      "tensor(0.3334)\n",
      "tensor(0.2958)\n",
      "tensor(0.2863)\n",
      "tensor(0.2606)\n",
      "tensor(0.3103)\n",
      "tensor(0.3460)\n",
      "tensor(0.3014)\n",
      "tensor(0.2516)\n",
      "tensor(0.2653)\n",
      "tensor(0.3666)\n",
      "tensor(0.3070)\n",
      "tensor(0.3181)\n",
      "tensor(0.2949)\n",
      "tensor(0.2734)\n",
      "tensor(0.3489)\n",
      "tensor(0.3416)\n",
      "tensor(0.2639)\n",
      "tensor(0.2627)\n",
      "tensor(0.2501)\n",
      "tensor(0.3619)\n",
      "tensor(0.2523)\n",
      "tensor(0.3419)\n",
      "tensor(0.2575)\n",
      "tensor(0.3524)\n",
      "tensor(0.2765)\n",
      "tensor(0.3377)\n",
      "tensor(0.3181)\n",
      "tensor(0.2674)\n",
      "tensor(0.2746)\n",
      "tensor(0.2843)\n",
      "tensor(0.3278)\n",
      "tensor(0.3122)\n",
      "tensor(0.2704)\n",
      "tensor(0.2664)\n",
      "tensor(0.2816)\n",
      "tensor(0.3257)\n",
      "tensor(0.2744)\n",
      "tensor(0.3563)\n",
      "tensor(0.3105)\n",
      "tensor(0.3083)\n",
      "tensor(0.2647)\n",
      "tensor(0.2761)\n",
      "tensor(0.2783)\n",
      "tensor(0.3869)\n",
      "tensor(0.3311)\n",
      "tensor(0.2707)\n",
      "tensor(0.3297)\n",
      "tensor(0.2927)\n",
      "tensor(0.3088)\n",
      "tensor(0.3108)\n",
      "tensor(0.2559)\n",
      "tensor(0.2582)\n",
      "tensor(0.2549)\n",
      "tensor(0.3196)\n",
      "tensor(0.2595)\n",
      "tensor(0.3256)\n",
      "tensor(0.2564)\n",
      "tensor(0.3363)\n",
      "tensor(0.2697)\n",
      "tensor(0.4811)\n",
      "tensor(0.4217)\n",
      "tensor(0.2708)\n",
      "tensor(0.3218)\n",
      "tensor(0.3367)\n",
      "tensor(0.3155)\n",
      "tensor(0.2747)\n",
      "tensor(0.3265)\n",
      "tensor(0.4180)\n",
      "tensor(0.3780)\n",
      "tensor(0.3898)\n",
      "tensor(0.2791)\n",
      "tensor(0.2931)\n",
      "tensor(0.2570)\n",
      "tensor(0.2731)\n",
      "tensor(0.2791)\n",
      "tensor(0.4916)\n",
      "tensor(0.3653)\n",
      "tensor(0.3062)\n",
      "tensor(0.2656)\n",
      "tensor(0.3128)\n",
      "tensor(0.3231)\n",
      "tensor(0.2698)\n",
      "tensor(0.2764)\n",
      "tensor(0.2698)\n",
      "tensor(0.4026)\n",
      "tensor(0.3265)\n",
      "tensor(0.2707)\n",
      "tensor(0.2518)\n",
      "tensor(0.2566)\n",
      "tensor(0.2586)\n",
      "tensor(0.3820)\n",
      "tensor(0.3076)\n",
      "tensor(0.2595)\n",
      "tensor(0.3915)\n",
      "tensor(0.2672)\n",
      "tensor(0.2526)\n",
      "tensor(0.3016)\n",
      "tensor(0.2986)\n",
      "tensor(0.3495)\n",
      "tensor(0.3186)\n",
      "tensor(0.3224)\n",
      "tensor(0.3009)\n",
      "tensor(0.3242)\n",
      "tensor(0.4135)\n",
      "tensor(0.2584)\n",
      "tensor(0.2757)\n",
      "tensor(0.2701)\n",
      "tensor(0.3242)\n",
      "tensor(0.2576)\n",
      "tensor(0.3278)\n",
      "tensor(0.2545)\n",
      "tensor(0.2778)\n",
      "tensor(0.2639)\n",
      "tensor(0.2691)\n",
      "tensor(0.2931)\n",
      "tensor(0.2610)\n",
      "tensor(0.2588)\n",
      "tensor(0.2624)\n",
      "tensor(0.2987)\n",
      "tensor(0.3498)\n",
      "tensor(0.4214)\n",
      "tensor(0.2735)\n",
      "tensor(0.2521)\n",
      "tensor(0.3530)\n",
      "tensor(0.2878)\n",
      "tensor(0.2628)\n",
      "tensor(0.4494)\n",
      "tensor(0.3603)\n",
      "tensor(0.2808)\n",
      "tensor(0.2793)\n",
      "tensor(0.2637)\n",
      "tensor(0.3656)\n",
      "tensor(0.4643)\n",
      "tensor(0.3174)\n",
      "tensor(0.2622)\n",
      "tensor(0.3273)\n",
      "tensor(0.2635)\n",
      "tensor(0.2639)\n",
      "tensor(0.2736)\n",
      "tensor(0.3377)\n",
      "tensor(0.3614)\n",
      "tensor(0.3825)\n",
      "tensor(0.2958)\n",
      "tensor(0.2666)\n",
      "tensor(0.5013)\n",
      "tensor(0.2506)\n",
      "tensor(0.3225)\n",
      "tensor(0.3411)\n",
      "tensor(0.3265)\n",
      "tensor(0.2567)\n",
      "tensor(0.3034)\n",
      "tensor(0.2624)\n",
      "tensor(0.3025)\n",
      "tensor(0.2940)\n",
      "tensor(0.2991)\n",
      "tensor(0.3043)\n",
      "tensor(0.3142)\n",
      "tensor(0.3240)\n",
      "tensor(0.4026)\n",
      "tensor(0.4976)\n",
      "tensor(0.3039)\n",
      "tensor(0.3529)\n",
      "tensor(0.2853)\n",
      "tensor(0.3272)\n",
      "tensor(0.3724)\n",
      "tensor(0.3489)\n",
      "tensor(0.2804)\n",
      "tensor(0.3034)\n",
      "tensor(0.2811)\n",
      "tensor(0.2543)\n",
      "tensor(0.2904)\n",
      "tensor(0.4443)\n",
      "tensor(0.3208)\n",
      "tensor(0.3794)\n",
      "tensor(0.2742)\n",
      "tensor(0.4017)\n",
      "tensor(0.3487)\n",
      "tensor(0.3361)\n",
      "tensor(0.3004)\n",
      "tensor(0.3718)\n",
      "tensor(0.3291)\n",
      "tensor(0.3053)\n",
      "tensor(0.3378)\n",
      "tensor(0.3730)\n",
      "tensor(0.2543)\n",
      "tensor(0.3036)\n",
      "tensor(0.2668)\n",
      "tensor(0.3248)\n",
      "tensor(0.2795)\n",
      "tensor(0.3024)\n",
      "tensor(0.2824)\n",
      "tensor(0.2622)\n",
      "tensor(0.3532)\n",
      "tensor(0.2742)\n",
      "tensor(0.2702)\n",
      "tensor(0.3039)\n",
      "tensor(0.2991)\n",
      "tensor(0.2638)\n",
      "tensor(0.3473)\n",
      "tensor(0.3021)\n",
      "tensor(0.2867)\n",
      "tensor(0.2567)\n",
      "tensor(0.2574)\n",
      "tensor(0.2882)\n",
      "tensor(0.2760)\n",
      "tensor(0.4019)\n",
      "tensor(0.2557)\n",
      "tensor(0.2521)\n",
      "tensor(0.2554)\n",
      "tensor(0.3571)\n",
      "tensor(0.2684)\n",
      "tensor(0.4106)\n",
      "tensor(0.2568)\n",
      "tensor(0.2502)\n",
      "tensor(0.3887)\n",
      "tensor(0.2519)\n",
      "tensor(0.3085)\n",
      "tensor(0.4752)\n",
      "tensor(0.3695)\n",
      "tensor(0.4781)\n",
      "tensor(0.2763)\n",
      "tensor(0.3267)\n",
      "tensor(0.2622)\n",
      "tensor(0.3867)\n",
      "tensor(0.2928)\n",
      "tensor(0.2793)\n",
      "tensor(0.2807)\n",
      "tensor(0.3324)\n",
      "tensor(0.3064)\n",
      "tensor(0.2659)\n",
      "tensor(0.2883)\n",
      "tensor(0.4387)\n",
      "tensor(0.2780)\n",
      "tensor(0.3186)\n",
      "tensor(0.3041)\n",
      "tensor(0.3226)\n",
      "tensor(0.3254)\n",
      "tensor(0.3325)\n",
      "tensor(0.2789)\n",
      "tensor(0.2555)\n",
      "tensor(0.2879)\n",
      "tensor(0.2566)\n",
      "tensor(0.2646)\n",
      "tensor(0.3366)\n",
      "tensor(0.4127)\n",
      "tensor(0.2918)\n",
      "tensor(0.2906)\n",
      "tensor(0.4180)\n",
      "tensor(0.2588)\n",
      "tensor(0.2725)\n",
      "tensor(0.2876)\n",
      "tensor(0.3576)\n",
      "tensor(0.3504)\n",
      "tensor(0.3007)\n",
      "tensor(0.2557)\n",
      "tensor(0.3118)\n",
      "tensor(0.3781)\n",
      "tensor(0.3328)\n",
      "tensor(0.2809)\n",
      "tensor(0.3907)\n",
      "tensor(0.2509)\n",
      "tensor(0.2673)\n",
      "tensor(0.3822)\n",
      "tensor(0.2974)\n",
      "tensor(0.2561)\n",
      "tensor(0.3851)\n",
      "tensor(0.3145)\n",
      "tensor(0.2559)\n",
      "tensor(0.3090)\n",
      "tensor(0.3307)\n",
      "tensor(0.2515)\n",
      "tensor(0.3061)\n",
      "tensor(0.2667)\n",
      "tensor(0.2727)\n",
      "tensor(0.3298)\n",
      "tensor(0.2577)\n",
      "tensor(0.2511)\n",
      "tensor(0.2921)\n",
      "tensor(0.3387)\n",
      "tensor(0.2725)\n",
      "tensor(0.2865)\n",
      "tensor(0.3314)\n",
      "tensor(0.2659)\n",
      "tensor(0.2639)\n",
      "tensor(0.2695)\n",
      "tensor(0.3020)\n",
      "tensor(0.2996)\n",
      "tensor(0.2671)\n",
      "tensor(0.2768)\n",
      "tensor(0.3159)\n",
      "tensor(0.2573)\n",
      "tensor(0.2509)\n",
      "tensor(0.2733)\n",
      "tensor(0.3316)\n",
      "tensor(0.2595)\n",
      "tensor(0.2551)\n",
      "tensor(0.2776)\n",
      "tensor(0.2614)\n",
      "tensor(0.3187)\n",
      "tensor(0.2837)\n",
      "tensor(0.2572)\n",
      "tensor(0.3220)\n",
      "tensor(0.2620)\n",
      "tensor(0.2536)\n",
      "tensor(0.2783)\n",
      "tensor(0.2853)\n",
      "tensor(0.2564)\n",
      "tensor(0.2696)\n",
      "tensor(0.2581)\n",
      "tensor(0.3599)\n",
      "tensor(0.3480)\n",
      "tensor(0.5684)\n",
      "tensor(0.4383)\n",
      "tensor(0.3454)\n",
      "tensor(0.2541)\n",
      "tensor(0.2762)\n",
      "tensor(0.2550)\n",
      "tensor(0.2548)\n",
      "tensor(0.2538)\n",
      "tensor(0.3893)\n",
      "tensor(0.3096)\n",
      "tensor(0.4667)\n",
      "tensor(0.2937)\n",
      "tensor(0.2807)\n",
      "tensor(0.2784)\n",
      "tensor(0.2636)\n",
      "tensor(0.2673)\n",
      "tensor(0.3036)\n",
      "tensor(0.4021)\n",
      "tensor(0.3027)\n",
      "tensor(0.3498)\n",
      "tensor(0.2828)\n",
      "tensor(0.4819)\n",
      "tensor(0.4650)\n",
      "tensor(0.4336)\n",
      "tensor(0.3934)\n",
      "tensor(0.4583)\n",
      "tensor(0.3811)\n",
      "tensor(0.4870)\n",
      "tensor(0.2708)\n",
      "tensor(0.3006)\n",
      "tensor(0.5616)\n",
      "tensor(0.2825)\n",
      "tensor(0.2718)\n",
      "tensor(0.3978)\n",
      "tensor(0.2930)\n",
      "tensor(0.3113)\n",
      "tensor(0.2559)\n",
      "tensor(0.2865)\n",
      "tensor(0.3471)\n",
      "tensor(0.2571)\n",
      "tensor(0.3003)\n",
      "tensor(0.2706)\n",
      "tensor(0.2968)\n",
      "tensor(0.2664)\n",
      "tensor(0.2735)\n",
      "tensor(0.2788)\n",
      "tensor(0.2988)\n",
      "tensor(0.3070)\n",
      "tensor(0.2761)\n",
      "tensor(0.3135)\n",
      "tensor(0.3454)\n",
      "tensor(0.2618)\n",
      "tensor(0.3321)\n",
      "tensor(0.3223)\n",
      "tensor(0.2946)\n",
      "tensor(0.3386)\n",
      "tensor(0.2551)\n",
      "tensor(0.2623)\n",
      "tensor(0.2750)\n",
      "tensor(0.2539)\n",
      "tensor(0.3832)\n",
      "tensor(0.2725)\n",
      "tensor(0.3093)\n",
      "tensor(0.3444)\n",
      "tensor(0.6595)\n",
      "tensor(0.2595)\n",
      "tensor(0.2792)\n",
      "tensor(0.4091)\n",
      "tensor(0.3220)\n",
      "tensor(0.3347)\n",
      "tensor(0.3922)\n",
      "tensor(0.2949)\n",
      "tensor(0.3034)\n",
      "tensor(0.2878)\n",
      "tensor(0.2553)\n",
      "tensor(0.3614)\n",
      "tensor(0.2847)\n",
      "tensor(0.2546)\n",
      "tensor(0.3027)\n",
      "tensor(0.3041)\n",
      "tensor(0.2674)\n",
      "tensor(0.3724)\n",
      "tensor(0.2519)\n",
      "tensor(0.2764)\n",
      "tensor(0.2699)\n",
      "tensor(0.6352)\n",
      "tensor(0.2502)\n",
      "tensor(0.3378)\n",
      "tensor(0.2765)\n",
      "tensor(0.4086)\n",
      "tensor(0.3496)\n",
      "tensor(0.2861)\n",
      "tensor(0.2624)\n",
      "tensor(0.2782)\n",
      "tensor(0.3039)\n",
      "tensor(0.2516)\n",
      "tensor(0.3014)\n",
      "tensor(0.5126)\n",
      "tensor(0.2958)\n",
      "tensor(0.2647)\n",
      "tensor(0.4735)\n",
      "tensor(0.3395)\n",
      "tensor(0.2644)\n",
      "tensor(0.2842)\n",
      "tensor(0.3549)\n",
      "tensor(0.4410)\n",
      "tensor(0.4006)\n",
      "tensor(0.3789)\n",
      "tensor(0.3009)\n",
      "tensor(0.3300)\n",
      "tensor(0.2674)\n",
      "tensor(0.3235)\n",
      "tensor(0.4257)\n",
      "tensor(0.3632)\n",
      "tensor(0.2761)\n",
      "tensor(0.2827)\n",
      "tensor(0.3401)\n",
      "tensor(0.3407)\n",
      "tensor(0.2929)\n",
      "tensor(0.4090)\n",
      "tensor(0.2558)\n",
      "tensor(0.2521)\n",
      "tensor(0.3766)\n",
      "tensor(0.2818)\n",
      "tensor(0.2573)\n",
      "tensor(0.3791)\n",
      "tensor(0.3901)\n",
      "tensor(0.2750)\n",
      "tensor(0.2796)\n",
      "tensor(0.3030)\n",
      "tensor(0.2798)\n",
      "tensor(0.3669)\n",
      "tensor(0.2940)\n",
      "tensor(0.3072)\n",
      "tensor(0.3454)\n",
      "tensor(0.2701)\n",
      "tensor(0.2734)\n",
      "tensor(0.4682)\n",
      "tensor(0.4170)\n",
      "tensor(0.3440)\n",
      "tensor(0.6412)\n",
      "tensor(0.4228)\n",
      "tensor(0.2874)\n",
      "tensor(0.2645)\n",
      "tensor(0.4249)\n",
      "tensor(0.3216)\n",
      "tensor(0.3311)\n",
      "tensor(0.2620)\n",
      "tensor(0.2948)\n",
      "tensor(0.2523)\n",
      "tensor(0.4422)\n",
      "tensor(0.3011)\n",
      "tensor(0.4510)\n",
      "tensor(0.3909)\n",
      "tensor(0.4078)\n",
      "tensor(0.3804)\n",
      "tensor(0.3019)\n",
      "tensor(0.2744)\n",
      "tensor(0.2657)\n",
      "tensor(0.2615)\n",
      "tensor(0.2647)\n",
      "tensor(0.2983)\n",
      "tensor(0.3116)\n",
      "tensor(0.2993)\n",
      "tensor(0.2728)\n",
      "tensor(0.2721)\n",
      "tensor(0.2870)\n",
      "tensor(0.3254)\n",
      "tensor(0.5451)\n",
      "tensor(0.3191)\n",
      "tensor(0.2591)\n",
      "tensor(0.2818)\n",
      "tensor(0.3169)\n",
      "tensor(0.2634)\n",
      "tensor(0.2910)\n",
      "tensor(0.3093)\n",
      "tensor(0.2560)\n",
      "tensor(0.2790)\n",
      "tensor(0.4565)\n",
      "tensor(0.3606)\n",
      "tensor(0.3943)\n",
      "tensor(0.2821)\n",
      "tensor(0.3249)\n",
      "tensor(0.3332)\n",
      "tensor(0.3612)\n",
      "tensor(0.2519)\n",
      "tensor(0.2965)\n",
      "tensor(0.2550)\n",
      "tensor(0.4280)\n",
      "tensor(0.3024)\n",
      "tensor(0.4466)\n",
      "tensor(0.2670)\n",
      "tensor(0.2940)\n",
      "tensor(0.2536)\n",
      "tensor(0.4272)\n",
      "tensor(0.3010)\n",
      "tensor(0.3093)\n",
      "tensor(0.2693)\n",
      "tensor(0.2665)\n",
      "tensor(0.4384)\n",
      "tensor(0.3470)\n",
      "tensor(0.2637)\n",
      "tensor(0.2913)\n",
      "tensor(0.2572)\n",
      "tensor(0.3661)\n",
      "tensor(0.2819)\n",
      "tensor(0.3992)\n",
      "tensor(0.2809)\n",
      "tensor(0.2507)\n",
      "tensor(0.3190)\n",
      "tensor(0.2576)\n",
      "tensor(0.2954)\n",
      "tensor(0.3273)\n",
      "tensor(0.3287)\n",
      "tensor(0.2799)\n",
      "tensor(0.2601)\n",
      "tensor(0.2592)\n",
      "tensor(0.3129)\n",
      "tensor(0.3030)\n",
      "tensor(0.2881)\n",
      "tensor(0.2522)\n",
      "tensor(0.2659)\n",
      "tensor(0.2716)\n",
      "tensor(0.2696)\n",
      "tensor(0.2712)\n",
      "tensor(0.2548)\n",
      "tensor(0.2770)\n",
      "tensor(0.2790)\n",
      "tensor(0.3380)\n",
      "tensor(0.3151)\n",
      "tensor(0.3291)\n",
      "tensor(0.2571)\n",
      "tensor(0.2695)\n",
      "tensor(0.2770)\n",
      "tensor(0.2539)\n",
      "tensor(0.2761)\n",
      "tensor(0.3697)\n",
      "tensor(0.2662)\n",
      "tensor(0.2928)\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "inputs = next(iter(tstdl)) \n",
    "print(\"number of samples: \" + str(len(inputs)))\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(inputs['X_ji'])\n",
    "    \n",
    "for output in outputs:\n",
    "    for inner_val in output:\n",
    "        if inner_val > 0.25:\n",
    "            print(inner_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884be6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = range(len(targets[0]))\n",
    "\n",
    "fig, axs = plt.subplots(8, 4, figsize=(20,15))\n",
    "for i in range(8):\n",
    "    for j in range(4):\n",
    "        axs[i, j].scatter(indices, targets[i+j*8], s=5)\n",
    "        axs[i, j].scatter(indices, outputs[i+j*8], s=5)\n",
    "        axs[i, j].set_ylim(-0.25, 2.25)\n",
    "\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Read Count')\n",
    "plt.legend(['True Read Count', 'Predicted Read Count'], loc='upper center', bbox_to_anchor=(0.5, -0.6))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
